{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_NMF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc8NsZqwwWiQ",
        "outputId": "3f2e348a-9a11-45f9-9bbf-e70645490c00"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        " \n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        " \n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import inv\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as I\n",
        "from torch.nn import Sigmoid\n",
        "\n",
        "\n",
        "from torch import transpose\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLvpBa0ZwyQy"
      },
      "source": [
        "## This Notebook Gave in SMR=0 SDR=2.57 and 2.45"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2r72nk9HrbY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def Viz_Y(t,f,Y, vmin=0, vmax=20):\n",
        "    plt.figure(figsize=(20,7))\n",
        "    plt.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    plt.title('STFT Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "\n",
        "def Reconstruct_2comp(n_components,B,G, Yabs):\n",
        "    \n",
        "    percents=[]\n",
        "    numerators=[]\n",
        "    \n",
        "    denominator = np.zeros((B.shape[0],G.shape[1]))\n",
        "    for i in range(n_components):\n",
        "    \n",
        "        denominator += np.matmul(B[:,i].reshape((B.shape[0],1)),G[i,:].reshape((1,G.shape[1])))\n",
        "        numerator = np.matmul(B[:,i].reshape((B.shape[0],1)),G[i,:].reshape((1,G.shape[1])))\n",
        "        numerators.append(numerator)\n",
        "\n",
        "        \n",
        "    for i in range(n_components):\n",
        "        \n",
        "        percents.append(numerators[i]/(denominator+0.001))\n",
        "    \n",
        "    \n",
        "    Sources=[]\n",
        "\n",
        "    for i in range(n_components):\n",
        "\n",
        "        Sources.append(np.multiply(percents[i],Yabs))\n",
        "\n",
        "    print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources\n",
        "\n",
        "\n",
        "def SMR(speech, music):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function that takes music and speech signals.\n",
        "    returns SMR in db\n",
        "    \"\"\"\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    SMR_db=10*np.log10(speech_power/music_power)\n",
        "    print('SMR = {:.2f}'.format(SMR_db))\n",
        "    \n",
        "    return SMR_db\n",
        "\n",
        "def SDR(s_est, s):\n",
        "    \"\"\"\n",
        "    Function that takes original and estimated spectrogram\n",
        "    returns SDR in DB\n",
        "    \"\"\"\n",
        "    \n",
        "    signal_power = LA.norm(s,2)\n",
        "    distorsion_power = LA.norm(s_est - s,2) \n",
        "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
        "    \n",
        "    return SDR_db\n",
        "\n",
        "def plot_SDR(list_smr,list_music,list_speech):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.set_style(\"darkgrid\")\n",
        "\n",
        "  ax1 = sns.lineplot(list_smr,list_music)\n",
        "  ax2 = sns.lineplot(list_smr,list_speech)\n",
        "  ax1.set(xlabel='SMR  (db)', ylabel='SMR  (db)')\n",
        "  ax1.legend([\"Estimated MUSIC signal\",\"Estimated SPEECH signal\"])\n",
        "  plt.show()\n",
        "  \n",
        "def get_mixed_signal(speech, music, SMR_db):\n",
        "    \"\"\"\n",
        "    Function taht takes the speech and music signal alongside the SMR_db\n",
        "    returns the mixed signal and the scaled speech\n",
        "    \"\"\"\n",
        "    smr = 10**(SMR_db/10)\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    scale = smr * music_power / speech_power\n",
        "    \n",
        "\n",
        "    \n",
        "    if SMR_db < 0 :\n",
        "        mixed = scale* speech + music\n",
        "        speech_scaled=scale*speech\n",
        "        SMR(speech_scaled,music)\n",
        "        return mixed,speech_scaled,music\n",
        "    \n",
        "    if SMR_db >= 0 :\n",
        "        \n",
        "        mixed =  speech + music * (1/scale)\n",
        "        music_scaled=(1/scale) * music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "\n",
        "def ReconstructSoft(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.exp(np.power(np.matmul(B1,G1),p)))\n",
        "    numerators.append(np.exp(np.power(np.matmul(B2,G2),p)))\n",
        "\n",
        "    denominator = np.power(np.exp(np.matmul(B1,G1)),p)+np.power(np.exp(np.matmul(B2,G2)),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYxUhmqBwXk8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from numpy import linalg as LA\n",
        "from numpy.linalg import inv\n",
        "#from helpers2 import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR,ReconstructSoft,butter_lowpass_filter\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idEcwxGxxkOd",
        "outputId": "afb6b85c-2db8-4b7f-8e6a-177f6d3d87b3"
      },
      "source": [
        "# Best 1-20 min\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100 \n",
        "\n",
        "samplerate_s, data_speech = read(\"/content/drive/MyDrive/Conversation.wav\")\n",
        "speech=data_speech[start:end,0]\n",
        "length=speech.shape[0]/samplerate_s\n",
        "print('Shape of the speech {} ... Length : {:.2f}s ... Sample rate : {}'.format(speech.shape[0],length,samplerate_s))\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 5 * 60 * 44100 \n",
        "samplerate_m, data_music = read(\"/content/drive/MyDrive/music.wav\")\n",
        "music=data_music[start:end,0]\n",
        "length=music.shape[0]/samplerate_m\n",
        "print('Shape of the music {} ... Length : {:.2f}s ... Sample rate : {}'.format(music.shape[0],length,samplerate_m))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the speech 50274000 ... Length : 1140.00s ... Sample rate : 44100\n",
            "Shape of the music 10584000 ... Length : 240.00s ... Sample rate : 44100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZEZdLJxo15",
        "outputId": "f7d47d08-27c8-45c5-ced9-cb9ffdd19722"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100\n",
        "\n",
        "\n",
        "speech_t=data_speech[start : end, 0]\n",
        "music_t = data_music[start : end, 0]\n",
        "\n",
        "\n",
        "speech_t = signal.resample(speech_t,int(speech_t.shape[0]/rate))\n",
        "music_t = signal.resample(music_t,int(music_t.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "print('Shape of the test {} ... Length : {:.2f}s ... Sample rate : {}'.format(music_t.shape[0],length,samplerate))\n",
        "\n",
        "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
        "music = signal.resample(music,int(music.shape[0]/rate))\n",
        "\n",
        "\n",
        "print('Downsampled rate = {}'.format(samplerate))\n",
        "\n",
        "speech = butter_lowpass_filter(speech,5000,fs)\n",
        "music = butter_lowpass_filter(music,5000,fs)\n",
        "\n",
        "music_t = butter_lowpass_filter(music_t,5000,fs)\n",
        "speech_t = butter_lowpass_filter(speech_t,5000,fs)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the test 18240000 ... Length : 1140.00s ... Sample rate : 16000\n",
            "Downsampled rate = 16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbke3Fm4zEG5"
      },
      "source": [
        "## Training STFT :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHbUgVOAyDiz",
        "outputId": "5e6a3721-e0fd-4e80-80df-646f6a0b6809"
      },
      "source": [
        "WINDOW = 'hamming'\n",
        "WINDOW_SIZE=480\n",
        "OVERLAP = 0.8 * WINDOW_SIZE\n",
        "NFFT=512\n",
        "\n",
        "f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_speech=np.abs(Y)\n",
        "f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_music=np.abs(Y)\n",
        "\n",
        "\n",
        "\n",
        "SMR_db = 0\n",
        "mix,speech_mix,music_mix=get_mixed_signal(speech_t,music_t,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ymix= signal.stft(mix,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_mix=np.abs(Ymix)\n",
        "\n",
        "Yabs_mix[Yabs_mix==0]=0.00001\n",
        "#write(\"/MixX.wav\", samplerate, mix.astype(np.int16))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTyG9UYBzIto"
      },
      "source": [
        "## Test STFT :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa1jCmT4yHq_",
        "outputId": "ed39bfa6-7ecc-4287-dace-eabfee015015"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = 15 * 60 * 44100\n",
        "step = int(1 * 60 * 44100)\n",
        "\n",
        "test_s = np.array([])\n",
        "test_m = np.array([])\n",
        "\n",
        "for i in range(1):\n",
        "\n",
        "  test_s = np.hstack([test_s,data_speech[start+i*step:start+(i+1)*step,0]])\n",
        "  test_m = np.hstack([test_m,data_music[start+i*step:start+(i+1)*step,0]])\n",
        "\n",
        "\n",
        "test_s = signal.resample(test_s,int(test_s.shape[0]/rate))\n",
        "test_m = signal.resample(test_m,int(test_m.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "\n",
        "test_s = butter_lowpass_filter(test_s,5000,fs)\n",
        "test_m = butter_lowpass_filter(test_m,5000,fs)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "SMR_db = 5\n",
        "test,speech_test,music_test=get_mixed_signal(test_s,test_m,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ytest= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_test=np.abs(Ytest)\n",
        "\n",
        "Yabs_test[Yabs_test==0]=0.00001\n"
      ],
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = 5.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjWdkHsOdDZ6"
      },
      "source": [
        "# Train First NMF on Clean Speech :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqeS3S86_Nw"
      },
      "source": [
        "def softmax(x):\n",
        "\n",
        "  e_x = np.exp(x)\n",
        "  return e_x / e_x.sum(axis=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc4PPRvnGrh5"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def Viz_Y(t,f,Y, vmin=0, vmax=20):\n",
        "    plt.figure(figsize=(20,7))\n",
        "    plt.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    plt.title('STFT Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def SMR(speech, music):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function that takes music and speech signals.\n",
        "    returns SMR in db\n",
        "    \"\"\"\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    SMR_db=10*np.log10(speech_power/music_power)\n",
        "    print('SMR = {:.2f}'.format(SMR_db))\n",
        "    \n",
        "    return SMR_db\n",
        "\n",
        "def SDR(s_est, s):\n",
        "    \"\"\"\n",
        "    Function that takes original and estimated spectrogram\n",
        "    returns SDR in DB\n",
        "    \"\"\"\n",
        "    \n",
        "    signal_power = LA.norm(s,2)\n",
        "    distorsion_power = LA.norm(s_est - s,2) \n",
        "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
        "    \n",
        "    return SDR_db\n",
        "\n",
        "def plot_SDR(list_smr,list_music,list_speech):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.set_style(\"darkgrid\")\n",
        "\n",
        "  ax1 = sns.lineplot(list_smr,list_music)\n",
        "  ax2 = sns.lineplot(list_smr,list_speech)\n",
        "  ax1.set(xlabel='SMR  (db)', ylabel='SMR  (db)')\n",
        "  ax1.legend([\"Estimated MUSIC signal\",\"Estimated SPEECH signal\"])\n",
        "  plt.show()\n",
        "  \n",
        "def get_mixed_signal(speech, music, SMR_db):\n",
        "    \"\"\"\n",
        "    Function taht takes the speech and music signal alongside the SMR_db\n",
        "    returns the mixed signal and the scaled speech\n",
        "    \"\"\"\n",
        "    smr = 10**(SMR_db/10)\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    scale = smr * music_power / speech_power\n",
        "    \n",
        "\n",
        "    \n",
        "    if SMR_db < 0 :\n",
        "        mixed = scale* speech + music\n",
        "        speech_scaled=scale*speech\n",
        "        SMR(speech_scaled,music)\n",
        "        return mixed,speech_scaled,music\n",
        "    \n",
        "    if SMR_db >= 0 :\n",
        "        \n",
        "        mixed =  speech + music * (1/scale)\n",
        "        music_scaled=(1/scale) * music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "\n",
        "\n",
        "def load_data(path_music,path_speech,sec):\n",
        "\n",
        "  samplerate_m,music = read(path_music)\n",
        "  music=music[:44100*sec,0]\n",
        "  length=music.shape[0]/samplerate_m\n",
        "  print('Shape of the music {}'.format(music.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_m))\n",
        "\n",
        "\n",
        "  samplerate_s,speech = read(path_speech)\n",
        "  speech=speech[:44100*sec,0]\n",
        "\n",
        "  length=speech.shape[0]/samplerate_s\n",
        "  print('Shape of the speech {}'.format(speech.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_s))\n",
        "\n",
        "  return music,speech,samplerate_s\n",
        "\n",
        "\n",
        "def Viz_Y(t,f,Y,Y_filtered, vmin=0, vmax=20):\n",
        "    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
        "    ax1.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    ax2.pcolormesh(t, f, Y_filtered,vmin=0, vmax=20, shading='gouraud')\n",
        "\n",
        "    plt.title('STFT Magnitude')\n",
        "    #ax.ylabel('Frequency [Hz]')\n",
        "    #ax.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "  \n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "#from helpers import *\n",
        "\n",
        "def speech_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G,model.reconstruction_err_\n",
        "def music_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G, model.reconstruction_err_\n",
        "\n",
        "\n",
        "\n",
        "def training(Yabs_music,\n",
        "               Yabs_speech,\n",
        "               init,\n",
        "               s_component = 128,\n",
        "               m_component = 128,\n",
        "               iterations = 200,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2,\n",
        "             samplerate=16000,\n",
        "                ):\n",
        "  ###################################   STFT   #######################################\n",
        "  S_abs = Yabs_speech\n",
        "  M_abs = Yabs_music\n",
        "  print(\"Training Stage ....\")\n",
        "  B_speech,_,error_speech = speech_nmf(S_abs,s_component,iterations,s_alpha,initt=init)\n",
        "  B_music,_,error_music =   music_nmf(M_abs,m_component,iterations,m_alpha,initt=init)\n",
        "  print(\"Training finish ! ....\")\n",
        "  #####################################################################################\n",
        "  B_mixed = np.concatenate([B_speech,B_music],axis = 1)                                # Concatenation of both  training dictionnaries\n",
        "  print(\"SPEECH reconstruction Loss {}\".format(error_speech))\n",
        "  print(\"MUSIC reconstruction Loss {}\".format(error_music))\n",
        "\n",
        "  return B_mixed\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBLPdOEGG_Dv"
      },
      "source": [
        "B_all_list= []\n",
        "for c in [10]:\n",
        "  B_mixed = training(Yabs_music,\n",
        "               Yabs_speech,\n",
        "               s_component = c,\n",
        "               m_component = c,\n",
        "               iterations = 100,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2,\n",
        "               init=\"random\")\n",
        "  B_mixed_new = MinMaxScaler().fit_transform(B_mixed)\n",
        "  B_all_list.append(B_mixed_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NWob8QfJ6_q"
      },
      "source": [
        "def mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              iterations,\n",
        "              a,\n",
        "              initt,\n",
        "              ):\n",
        "  n_components=B_mixed.shape[1]\n",
        "  model = NMF(n_components=n_components,\n",
        "              init=initt,\n",
        "              alpha=a,\n",
        "              beta_loss='itakura-saito',\n",
        "              solver=\"mu\",\n",
        "              max_iter=iterations,\n",
        "              random_state=0)\n",
        "  \n",
        "  model.fit(np.transpose(Yabs_test))\n",
        "\n",
        "  model.components_ = np.transpose(B_mixed)\n",
        "\n",
        "  G0 = model.transform(np.transpose(Yabs_test))\n",
        "\n",
        "  return np.transpose(G0),model.reconstruction_err_,model.components_\n",
        "\n",
        "def validation(B_mixed,\n",
        "               speech,\n",
        "               music,\n",
        "               s_component,\n",
        "               m_component,\n",
        "               alpha,\n",
        "               init,\n",
        "               smr,\n",
        "               iterations,\n",
        "               samplerate=16000\n",
        "               ):\n",
        "\n",
        "\n",
        "  G_mixed,reconstruction,update_or_not = mixed_nmf(B_mixed,\n",
        "              mixed_abs,\n",
        "              iterations,\n",
        "              alpha,\n",
        "              init\n",
        "              )\n",
        "  return B_mixed, G_mixed"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYfL9S6CALT"
      },
      "source": [
        "B_mixed = np.load(\"B_trained_nmf.npy\")\n",
        "G,_,B = mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              100,\n",
        "              0,\n",
        "              'random',\n",
        "              )"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a95xH_lICt0g"
      },
      "source": [
        "def eval(D,G_test,Ytest):\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  sdr_speech = SDR(s_est=speech_est,s=test_s)\n",
        "  sdr_music = SDR(s_est=music_est, s=test_m)\n",
        "\n",
        "  print(f'Speech SDR = {sdr_speech}')\n",
        "  print(f'Music SDR = {sdr_music}')"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vxkBgvYCmAs",
        "outputId": "42119382-6361-47b0-8417-a6d9974f1c93"
      },
      "source": [
        "eval(np.transpose(B),G,Ytest)"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n",
            "Speech SDR = 3.616840374783834\n",
            "Music SDR = 0.4735498443366221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFuEl_CDOXX"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0jOM1lDOwA",
        "outputId": "42d2f390-d901-42f4-b364-dd782c1926c6"
      },
      "source": [
        "Sources,Masks=Reconstruct(B=np.transpose(B),G=G,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "print('Reconstruction Step .... Done')\n",
        "speech_est = Sources[0]\n",
        "music_est = Sources[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0PNgtTwDSkP"
      },
      "source": [
        "class DNN(nn.Module):\n",
        "\n",
        "    def __init__(self,d):\n",
        "        super(DNN, self).__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(d, 10,bias=False) \n",
        "        self.fc2 = nn.Linear(10, 5,bias=False) \n",
        "        self.fc3 = nn.Linear(5, 10,bias=False) \n",
        "        self.fc4 = nn.Linear(10, 20,bias=False) \n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.Dropout(0.8)(self.relu(self.fc1(x)))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": 510,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z66_n2BSDnuk"
      },
      "source": [
        "dnn_model = DNN(d=20)\n"
      ],
      "execution_count": 511,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNXMGoxcUQzh",
        "outputId": "cc5aca05-a109-40be-ae65-d11a5991918e"
      },
      "source": [
        "B_mixed.shape"
      ],
      "execution_count": 512,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(257, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 512
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGCLV-6xDp7C",
        "outputId": "0e3778ef-5a65-4f5d-ae0e-7dc78a6b37b1"
      },
      "source": [
        "from  helpers_dnn import *\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 513,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEM-O46wXU3X"
      },
      "source": [
        "\n",
        "model = DNN(20)\n",
        "b = torch.from_numpy(MinMaxScaler().fit_transform(B_mixed)).float()\n",
        "h = torch.from_numpy(G).float()\n",
        "y = torch.from_numpy(Yabs_test).float()\n",
        "\n",
        "#b = torch.tensor(B_t).to(device)\n",
        "#b = torch.tensor(B_t).to(device)\n"
      ],
      "execution_count": 514,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYO89WTEE2M5"
      },
      "source": [
        "def train_model(train,\n",
        "                y,\n",
        "                h,\n",
        "                model,\n",
        "                learning_rate=0.001,\n",
        "                batch_size = 1,\n",
        "                num_epochs=50,\n",
        "                factor_scheduler = 0.8):\n",
        "  \n",
        "  print(\"begin....\")\n",
        "\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)\n",
        "  \n",
        "  train_numpy = np.array(train,dtype=\"float32\")\n",
        "  train_y = np.array(np.transpose(y),dtype=\"float32\")\n",
        "  train_h= np.array(np.transpose(h),dtype=\"float32\")\n",
        "\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_numpy,batch_size = batch_size)\n",
        "  train_Y = torch.utils.data.DataLoader(train_y,batch_size = batch_size)\n",
        "  train_H = torch.utils.data.DataLoader(train_h,batch_size = batch_size)\n",
        "\n",
        "  train_hist = np.zeros(num_epochs)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                         min_lr = 1e-7,\n",
        "                                                         mode = 'min',\n",
        "                                                         factor=factor_scheduler,\n",
        "                                                         verbose=True\n",
        "                                                         ,patience=100)\n",
        "\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    for y,h in zip(train_Y,train_H):\n",
        "      optimizer.zero_grad()\n",
        "      reconstructed = model(train)\n",
        "\n",
        "      loss = torch.nn.MSELoss()(y.t(),reconstructed@h.t())\n",
        "      train_hist[e] = loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "    if e%1 == 0:\n",
        "      print(f'Epoch {e} train loss:{loss.item()}')\n",
        "\n",
        "  print(\"finish !\")\n",
        "  return model.eval(), train_hist"
      ],
      "execution_count": 515,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZURv8fFnsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a451680e-42ca-4fb9-89d1-e09e713b6cc1"
      },
      "source": [
        "model = DNN(20)\n",
        "\n",
        "model,train_hist = train_model(b,y,h,\n",
        "                model,\n",
        "                learning_rate=0.01,\n",
        "                batch_size = 1,\n",
        "                num_epochs=1,\n",
        "                factor_scheduler = 0.8)"
      ],
      "execution_count": 517,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin....\n",
            "Epoch 0 train loss:1388.1180419921875\n",
            "finish !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCLKYxnbpMpT",
        "outputId": "767d242d-0fba-4f53-f62b-0f39d95cc951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 518,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([257, 10001])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 518
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eFOeVe6F_o7"
      },
      "source": [
        "a = model(s1).detach().numpy()"
      ],
      "execution_count": 519,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FVNH03P2-eJ",
        "outputId": "eff513fa-1737-41bb-e5cf-90337bdcde17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "sns.distplot(a)"
      ],
      "execution_count": 520,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f88fa938990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 520
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH5bakAsWgR2",
        "outputId": "36d5b178-f5b5-4145-bae8-f28f6c6f7768"
      },
      "source": [
        "a[a ==0] = 0.00000000001\n",
        "eval(a ,G,Ytest)"
      ],
      "execution_count": 521,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n",
            "Speech SDR = 4.890741914963148\n",
            "Music SDR = 0.5622547531279469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02kqzppIsBvT"
      },
      "source": [
        "def eval(D,G_test,Ytest):\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  sdr_speech = SDR(s_est=speech_est,s=test_s)\n",
        "  sdr_music = SDR(s_est=music_est, s=test_m)\n",
        "  np.savetxt(\"speech_nmf\",speech_est)\n",
        "  print(f'Speech SDR = {sdr_speech}')\n",
        "  print(f'Music SDR = {sdr_music}')"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWK2nkIP3fAg"
      },
      "source": [
        "np.savetxt(\"speech_original\",test_s)"
      ],
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tINBUCII3lp2",
        "outputId": "e9727207-b488-4b51-a35e-4024c20b947b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval(np.transpose(B) ,G,Ytest)"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n",
            "Speech SDR = 3.616840374783834\n",
            "Music SDR = 0.4735498443366221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEJS0HLu4li-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}