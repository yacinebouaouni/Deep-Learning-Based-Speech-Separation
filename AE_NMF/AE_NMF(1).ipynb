{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_NMF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc8NsZqwwWiQ",
        "outputId": "ad0a4c3f-cf92-4d22-f2cd-402fcbb14d0b"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        " \n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        " \n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import inv\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as I\n",
        "from torch.nn import Sigmoid\n",
        "\n",
        "\n",
        "from torch import transpose\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLvpBa0ZwyQy"
      },
      "source": [
        "## This Notebook Gave in SMR=0 SDR=2.57 and 2.45"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndjAVIu98HGL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bpxizni9Jyv"
      },
      "source": [
        "!apt install octave\n",
        "!apt install liboctave-dev  # development files\n",
        "!pip3 install oct2py\n",
        "from oct2py import Oct2Py\n",
        "oc = Oct2Py()\n",
        "script = '''\n",
        "  function [SDR,SIR,SAR,perm]=bss_eval_sources(se,s)\n",
        "%%% Errors %%%\n",
        "if nargin<2, error('Not enough input arguments.'); end\n",
        "[nsrc,nsampl]=size(se);\n",
        "[nsrc2,nsampl2]=size(s);\n",
        "if nsrc2~=nsrc, error('The number of estimated sources and reference sources must be equal.'); end\n",
        "if nsampl2~=nsampl, error('The estimated sources and reference sources must have the same duration.'); end\n",
        "\n",
        "%%% Performance criteria %%%\n",
        "% Computation of the criteria for all possible pair matches\n",
        "SDR=zeros(nsrc,nsrc);\n",
        "SIR=zeros(nsrc,nsrc);\n",
        "SAR=zeros(nsrc,nsrc);\n",
        "for jest=1:nsrc,\n",
        "    for jtrue=1:nsrc,\n",
        "        [s_true,e_spat,e_interf,e_artif]=bss_decomp_mtifilt(se(jest,:),s,jtrue,512);\n",
        "        [SDR(jest,jtrue),SIR(jest,jtrue),SAR(jest,jtrue)]=bss_source_crit(s_true,e_spat,e_interf,e_artif);\n",
        "    end\n",
        "end\n",
        "% Selection of the best ordering\n",
        "perm=perms(1:nsrc);\n",
        "nperm=size(perm,1);\n",
        "meanSIR=zeros(nperm,1);\n",
        "for p=1:nperm,\n",
        "    meanSIR(p)=mean(SIR((0:nsrc-1)*nsrc+perm(p,:)));\n",
        "end\n",
        "[meanSIR,popt]=max(meanSIR);\n",
        "perm=perm(popt,:).';\n",
        "SDR=SDR((0:nsrc-1).'*nsrc+perm);\n",
        "SIR=SIR((0:nsrc-1).'*nsrc+perm);\n",
        "SAR=SAR((0:nsrc-1).'*nsrc+perm);\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "\n",
        "function [s_true,e_spat,e_interf,e_artif]=bss_decomp_mtifilt(se,s,j,flen)\n",
        "\n",
        "if nargin<4, error('Not enough input arguments.'); end\n",
        "[nchan2,nsampl2]=size(se);\n",
        "[nsrc,nsampl,nchan]=size(s);\n",
        "if nchan2~=nchan, error('The number of channels of the true source images and the estimated source image must be equal.'); end\n",
        "if nsampl2~=nsampl, error('The duration of the true source images and the estimated source image must be equal.'); end\n",
        "\n",
        "%%% Decomposition %%%\n",
        "% True source image\n",
        "s_true=[reshape(s(j,:,:),nsampl,nchan).',zeros(nchan,flen-1)];\n",
        "% Spatial (or filtering) distortion\n",
        "e_spat=project(se,s(j,:,:),flen)-s_true;\n",
        "% Interference\n",
        "e_interf=project(se,s,flen)-s_true-e_spat;\n",
        "% Artifacts\n",
        "e_artif=[se,zeros(nchan,flen-1)]-s_true-e_spat-e_interf;\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "\n",
        "function sproj=project(se,s,flen)\n",
        "\n",
        "% SPROJ Least-squares projection of each channel of se on the subspace\n",
        "% spanned by delayed versions of the channels of s, with delays between 0\n",
        "% and flen-1\n",
        "\n",
        "[nsrc,nsampl,nchan]=size(s);\n",
        "s=reshape(permute(s,[3 1 2]),nchan*nsrc,nsampl);\n",
        "\n",
        "%%% Computing coefficients of least squares problem via FFT %%%\n",
        "% Zero padding and FFT of input data\n",
        "s=[s,zeros(nchan*nsrc,flen-1)];\n",
        "se=[se,zeros(nchan,flen-1)];\n",
        "fftlen=2^nextpow2(nsampl+flen-1);\n",
        "sf=fft(s,fftlen,2);\n",
        "sef=fft(se,fftlen,2);\n",
        "% Inner products between delayed versions of s\n",
        "G=zeros(nchan*nsrc*flen);\n",
        "for k1=0:nchan*nsrc-1,\n",
        "    for k2=0:k1,\n",
        "        ssf=sf(k1+1,:).*conj(sf(k2+1,:));\n",
        "        ssf=real(ifft(ssf));\n",
        "        ss=toeplitz(ssf([1 fftlen:-1:fftlen-flen+2]),ssf(1:flen));\n",
        "        G(k1*flen+1:k1*flen+flen,k2*flen+1:k2*flen+flen)=ss;\n",
        "        G(k2*flen+1:k2*flen+flen,k1*flen+1:k1*flen+flen)=ss.';\n",
        "    end\n",
        "end\n",
        "% Inner products between se and delayed versions of s\n",
        "D=zeros(nchan*nsrc*flen,nchan);\n",
        "for k=0:nchan*nsrc-1,\n",
        "    for i=1:nchan,\n",
        "        ssef=sf(k+1,:).*conj(sef(i,:));\n",
        "        ssef=real(ifft(ssef,[],2));\n",
        "        D(k*flen+1:k*flen+flen,i)=ssef(:,[1 fftlen:-1:fftlen-flen+2]).';\n",
        "    end\n",
        "end\n",
        "\n",
        "%%% Computing projection %%%\n",
        "% Distortion filters\n",
        "C=G\\D;\n",
        "C=reshape(C,flen,nchan*nsrc,nchan);\n",
        "% Filtering\n",
        "sproj=zeros(nchan,nsampl+flen-1);\n",
        "for k=1:nchan*nsrc,\n",
        "    for i=1:nchan,\n",
        "        sproj(i,:)=sproj(i,:)+fftfilt(C(:,k,i).',s(k,:));\n",
        "    end\n",
        "end\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "\n",
        "function [SDR,SIR,SAR]=bss_source_crit(s_true,e_spat,e_interf,e_artif)\n",
        "\n",
        "\n",
        "if nargin<4, error('Not enough input arguments.'); end\n",
        "[nchant,nsamplt]=size(s_true);\n",
        "[nchans,nsampls]=size(e_spat);\n",
        "[nchani,nsampli]=size(e_interf);\n",
        "[nchana,nsampla]=size(e_artif);\n",
        "if ~((nchant==nchans)&&(nchant==nchani)&&(nchant==nchana)), error('All the components must have the same number of channels.'); end\n",
        "if ~((nsamplt==nsampls)&&(nsamplt==nsampli)&&(nsamplt==nsampla)), error('All the components must have the same duration.'); end\n",
        "\n",
        "%%% Energy ratios %%%\n",
        "s_filt=s_true+e_spat;\n",
        "% SDR\n",
        "SDR=10*log10(sum(sum(s_filt.^2))/sum(sum((e_interf+e_artif).^2)))\n",
        "% SIR\n",
        "SIR=10*log10(sum(sum(s_filt.^2))/sum(sum(e_interf.^2)));\n",
        "% SA\n",
        "SAR=10*log10(sum(sum((s_filt+e_interf).^2))/sum(sum(e_artif.^2)));\n",
        "return;\n",
        "\n",
        "         '''\n",
        "\n",
        "with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2r72nk9HrbY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def Viz_Y(t,f,Y, vmin=0, vmax=20):\n",
        "    plt.figure(figsize=(20,7))\n",
        "    plt.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    plt.title('STFT Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "\n",
        "def Reconstruct_2comp(n_components,B,G, Yabs):\n",
        "    \n",
        "    percents=[]\n",
        "    numerators=[]\n",
        "    \n",
        "    denominator = np.zeros((B.shape[0],G.shape[1]))\n",
        "    for i in range(n_components):\n",
        "    \n",
        "        denominator += np.matmul(B[:,i].reshape((B.shape[0],1)),G[i,:].reshape((1,G.shape[1])))\n",
        "        numerator = np.matmul(B[:,i].reshape((B.shape[0],1)),G[i,:].reshape((1,G.shape[1])))\n",
        "        numerators.append(numerator)\n",
        "\n",
        "        \n",
        "    for i in range(n_components):\n",
        "        \n",
        "        percents.append(numerators[i]/(denominator+0.001))\n",
        "    \n",
        "    \n",
        "    Sources=[]\n",
        "\n",
        "    for i in range(n_components):\n",
        "\n",
        "        Sources.append(np.multiply(percents[i],Yabs))\n",
        "\n",
        "    print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources\n",
        "\n",
        "\n",
        "def SMR(speech, music):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function that takes music and speech signals.\n",
        "    returns SMR in db\n",
        "    \"\"\"\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    SMR_db=10*np.log10(speech_power/music_power)\n",
        "    print('SMR = {:.2f}'.format(SMR_db))\n",
        "    \n",
        "    return SMR_db\n",
        "\n",
        "def SDR(s_est, s):\n",
        "    \"\"\"\n",
        "    Function that takes original and estimated spectrogram\n",
        "    returns SDR in DB\n",
        "    \"\"\"\n",
        "    \n",
        "    signal_power = LA.norm(s,2)\n",
        "    distorsion_power = LA.norm(s_est - s,2) \n",
        "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
        "    \n",
        "    return SDR_db\n",
        "\n",
        "def plot_SDR(list_smr,list_music,list_speech):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.set_style(\"darkgrid\")\n",
        "\n",
        "  ax1 = sns.lineplot(list_smr,list_music)\n",
        "  ax2 = sns.lineplot(list_smr,list_speech)\n",
        "  ax1.set(xlabel='SMR  (db)', ylabel='SMR  (db)')\n",
        "  ax1.legend([\"Estimated MUSIC signal\",\"Estimated SPEECH signal\"])\n",
        "  plt.show()\n",
        "  \n",
        "def get_mixed_signal(speech, music, SMR_db):\n",
        "    \"\"\"\n",
        "    Function taht takes the speech and music signal alongside the SMR_db\n",
        "    returns the mixed signal and the scaled speech\n",
        "    \"\"\"\n",
        "    smr = 10**(SMR_db/10)\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    scale = smr * music_power / speech_power\n",
        "    \n",
        "\n",
        "    \n",
        "    if SMR_db < 0 :\n",
        "        mixed = scale* speech + music\n",
        "        speech_scaled=scale*speech\n",
        "        SMR(speech_scaled,music)\n",
        "        return mixed,speech_scaled,music\n",
        "    \n",
        "    if SMR_db >= 0 :\n",
        "        \n",
        "        mixed =  speech + music * (1/scale)\n",
        "        music_scaled=(1/scale) * music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "\n",
        "def ReconstructSoft(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.exp(np.power(np.matmul(B1,G1),p)))\n",
        "    numerators.append(np.exp(np.power(np.matmul(B2,G2),p)))\n",
        "\n",
        "    denominator = np.power(np.exp(np.matmul(B1,G1)),p)+np.power(np.exp(np.matmul(B2,G2)),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYxUhmqBwXk8"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from numpy import linalg as LA\n",
        "from numpy.linalg import inv\n",
        "#from helpers2 import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR,ReconstructSoft,butter_lowpass_filter\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "warnings.simplefilter('ignore')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idEcwxGxxkOd",
        "outputId": "867bfdc6-40f3-438c-b3c0-b2405888c6f6"
      },
      "source": [
        "# Best 1-20 min\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100 \n",
        "\n",
        "samplerate_s, data_speech = read(\"/content/drive/MyDrive/Conversation.wav\")\n",
        "speech=data_speech[start:end,0]\n",
        "length=speech.shape[0]/samplerate_s\n",
        "print('Shape of the speech {} ... Length : {:.2f}s ... Sample rate : {}'.format(speech.shape[0],length,samplerate_s))\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100 \n",
        "samplerate_m, data_music = read(\"/content/drive/MyDrive/music.wav\")\n",
        "music=data_music[start:end,0]\n",
        "length=music.shape[0]/samplerate_m\n",
        "print('Shape of the music {} ... Length : {:.2f}s ... Sample rate : {}'.format(music.shape[0],length,samplerate_m))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the speech 50274000 ... Length : 1140.00s ... Sample rate : 44100\n",
            "Shape of the music 50274000 ... Length : 1140.00s ... Sample rate : 44100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZEZdLJxo15",
        "outputId": "c38a41c7-ac48-4a9a-8a74-251ffbdb62b4"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100\n",
        "\n",
        "\n",
        "speech_t=data_speech[start : end, 0]\n",
        "music_t = data_music[start : end, 0]\n",
        "\n",
        "\n",
        "speech_t = signal.resample(speech_t,int(speech_t.shape[0]/rate))\n",
        "music_t = signal.resample(music_t,int(music_t.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "print('Shape of the test {} ... Length : {:.2f}s ... Sample rate : {}'.format(music_t.shape[0],length,samplerate))\n",
        "\n",
        "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
        "music = signal.resample(music,int(music.shape[0]/rate))\n",
        "\n",
        "\n",
        "print('Downsampled rate = {}'.format(samplerate))\n",
        "\n",
        "speech = butter_lowpass_filter(speech,5000,fs)\n",
        "music = butter_lowpass_filter(music,5000,fs)\n",
        "\n",
        "music_t = butter_lowpass_filter(music_t,5000,fs)\n",
        "speech_t = butter_lowpass_filter(speech_t,5000,fs)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the test 18240000 ... Length : 1140.00s ... Sample rate : 16000\n",
            "Downsampled rate = 16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbke3Fm4zEG5"
      },
      "source": [
        "## Training STFT :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHbUgVOAyDiz",
        "outputId": "e204502c-c740-4f76-89a9-9ac4139accb2"
      },
      "source": [
        "WINDOW = 'hamming'\n",
        "WINDOW_SIZE=480\n",
        "OVERLAP = 0.8 * WINDOW_SIZE\n",
        "NFFT=512\n",
        "\n",
        "f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_speech=np.abs(Y)\n",
        "f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_music=np.abs(Y)\n",
        "\n",
        "\n",
        "\n",
        "SMR_db = 5\n",
        "mix,speech_mix,music_mix=get_mixed_signal(speech_t,music_t,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ymix= signal.stft(mix,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_mix=np.abs(Ymix)\n",
        "\n",
        "Yabs_mix[Yabs_mix==0]=0.00001\n",
        "#write(\"/MixX.wav\", samplerate, mix.astype(np.int16))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = 5.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTyG9UYBzIto"
      },
      "source": [
        "## Test STFT :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa1jCmT4yHq_",
        "outputId": "69147496-bbfe-45ff-f9e9-f0177133c10c"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = 15 * 60 * 44100\n",
        "step = int(1 * 60 * 44100)\n",
        "\n",
        "test_s = np.array([])\n",
        "test_m = np.array([])\n",
        "\n",
        "for i in range(1):\n",
        "\n",
        "  test_s = np.hstack([test_s,data_speech[start+i*step:start+(i+1)*step,0]])\n",
        "  test_m = np.hstack([test_m,data_music[start+i*step:start+(i+1)*step,0]])\n",
        "\n",
        "\n",
        "test_s = signal.resample(test_s,int(test_s.shape[0]/rate))\n",
        "test_m = signal.resample(test_m,int(test_m.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "\n",
        "test_s = butter_lowpass_filter(test_s,5000,fs)\n",
        "test_m = butter_lowpass_filter(test_m,5000,fs)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "SMR_db = 0\n",
        "test,speech_test,music_test=get_mixed_signal(test_s,test_m,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ytest= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_test=np.abs(Ytest)\n",
        "\n",
        "Yabs_test[Yabs_test==0]=0.00001\n"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjWdkHsOdDZ6"
      },
      "source": [
        "# Train First NMF on Clean Speech :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqeS3S86_Nw"
      },
      "source": [
        "def softmax(x):\n",
        "\n",
        "  e_x = np.exp(x)\n",
        "  return e_x / e_x.sum(axis=0)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc4PPRvnGrh5"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def Viz_Y(t,f,Y, vmin=0, vmax=20):\n",
        "    plt.figure(figsize=(20,7))\n",
        "    plt.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    plt.title('STFT Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def SMR(speech, music):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function that takes music and speech signals.\n",
        "    returns SMR in db\n",
        "    \"\"\"\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    SMR_db=10*np.log10(speech_power/music_power)\n",
        "    print('SMR = {:.2f}'.format(SMR_db))\n",
        "    \n",
        "    return SMR_db\n",
        "\n",
        "def SDR(s_est, s):\n",
        "    \"\"\"\n",
        "    Function that takes original and estimated spectrogram\n",
        "    returns SDR in DB\n",
        "    \"\"\"\n",
        "    \n",
        "    signal_power = LA.norm(s,2)\n",
        "    distorsion_power = LA.norm(s_est - s,2) \n",
        "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
        "    \n",
        "    return SDR_db\n",
        "\n",
        "def plot_SDR(list_smr,list_music,list_speech):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.set_style(\"darkgrid\")\n",
        "\n",
        "  ax1 = sns.lineplot(list_smr,list_music)\n",
        "  ax2 = sns.lineplot(list_smr,list_speech)\n",
        "  ax1.set(xlabel='SMR  (db)', ylabel='SMR  (db)')\n",
        "  ax1.legend([\"Estimated MUSIC signal\",\"Estimated SPEECH signal\"])\n",
        "  plt.show()\n",
        "  \n",
        "def get_mixed_signal(speech, music, SMR_db):\n",
        "    \"\"\"\n",
        "    Function taht takes the speech and music signal alongside the SMR_db\n",
        "    returns the mixed signal and the scaled speech\n",
        "    \"\"\"\n",
        "    smr = 10**(SMR_db/10)\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    scale = smr * music_power / speech_power\n",
        "    \n",
        "\n",
        "    \n",
        "    if SMR_db < 0 :\n",
        "        mixed = scale* speech + music\n",
        "        speech_scaled=scale*speech\n",
        "        SMR(speech_scaled,music)\n",
        "        return mixed,speech_scaled,music\n",
        "    \n",
        "    if SMR_db >= 0 :\n",
        "        \n",
        "        mixed =  speech + music * (1/scale)\n",
        "        music_scaled=(1/scale) * music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "\n",
        "\n",
        "def load_data(path_music,path_speech,sec):\n",
        "\n",
        "  samplerate_m,music = read(path_music)\n",
        "  music=music[:44100*sec,0]\n",
        "  length=music.shape[0]/samplerate_m\n",
        "  print('Shape of the music {}'.format(music.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_m))\n",
        "\n",
        "\n",
        "  samplerate_s,speech = read(path_speech)\n",
        "  speech=speech[:44100*sec,0]\n",
        "\n",
        "  length=speech.shape[0]/samplerate_s\n",
        "  print('Shape of the speech {}'.format(speech.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_s))\n",
        "\n",
        "  return music,speech,samplerate_s\n",
        "\n",
        "\n",
        "def Viz_Y(t,f,Y,Y_filtered, vmin=0, vmax=20):\n",
        "    fig,(ax1,ax2) = plt.subplots(1,2,figsize=(10,5))\n",
        "    ax1.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    ax2.pcolormesh(t, f, Y_filtered,vmin=0, vmax=20, shading='gouraud')\n",
        "\n",
        "    plt.title('STFT Magnitude')\n",
        "    #ax.ylabel('Frequency [Hz]')\n",
        "    #ax.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "  \n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "#from helpers import *\n",
        "\n",
        "def speech_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G,model.reconstruction_err_\n",
        "def music_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G, model.reconstruction_err_\n",
        "\n",
        "\n",
        "\n",
        "def training(Yabs_music,\n",
        "               Yabs_speech,\n",
        "               init,\n",
        "               s_component = 128,\n",
        "               m_component = 128,\n",
        "               iterations = 200,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2,\n",
        "             samplerate=16000,\n",
        "                ):\n",
        "  ###################################   STFT   #######################################\n",
        "  S_abs = Yabs_speech\n",
        "  M_abs = Yabs_music\n",
        "  print(\"Training Stage ....\")\n",
        "  B_speech,_,error_speech = speech_nmf(S_abs,s_component,iterations,s_alpha,initt=init)\n",
        "  B_music,_,error_music =   music_nmf(M_abs,m_component,iterations,m_alpha,initt=init)\n",
        "  print(\"Training finish ! ....\")\n",
        "  #####################################################################################\n",
        "  B_mixed = np.concatenate([B_speech,B_music],axis = 1)                                # Concatenation of both  training dictionnaries\n",
        "  print(\"SPEECH reconstruction Loss {}\".format(error_speech))\n",
        "  print(\"MUSIC reconstruction Loss {}\".format(error_music))\n",
        "\n",
        "  return B_mixed\n",
        "\n"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ozA9AeqZhnT",
        "outputId": "a2aaef52-ab7b-41b9-9597-37278d3d7b94"
      },
      "source": [
        "Yabs_music.shape, Yabs_speech.shape"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((257, 190001), (257, 190001))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NWob8QfJ6_q"
      },
      "source": [
        "def mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              iterations,\n",
        "              a,\n",
        "              initt,\n",
        "              ):\n",
        "  n_components=B_mixed.shape[1]\n",
        "  model = NMF(n_components=n_components,\n",
        "              init=initt,\n",
        "              alpha=a,\n",
        "              beta_loss='itakura-saito',\n",
        "              solver=\"mu\",\n",
        "              max_iter=iterations,\n",
        "              random_state=0)\n",
        "  \n",
        "  model.fit(np.transpose(Yabs_test))\n",
        "\n",
        "  model.components_ = np.transpose(B_mixed)\n",
        "\n",
        "  G0 = model.transform(np.transpose(Yabs_test))\n",
        "\n",
        "  return np.transpose(G0),model.reconstruction_err_,model.components_\n",
        "\n",
        "def validation(B_mixed,\n",
        "               speech,\n",
        "               music,\n",
        "               s_component,\n",
        "               m_component,\n",
        "               alpha,\n",
        "               init,\n",
        "               smr,\n",
        "               iterations,\n",
        "               samplerate=16000\n",
        "               ):\n",
        "\n",
        "\n",
        "  G_mixed,reconstruction,update_or_not = mixed_nmf(B_mixed,\n",
        "              mixed_abs,\n",
        "              iterations,\n",
        "              alpha,\n",
        "              init\n",
        "              )\n",
        "  return B_mixed, G_mixed"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYfL9S6CALT"
      },
      "source": [
        "B_mixed = np.load(\"B_trained_nmf.npy\")\n",
        "G,_,B = mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              100,\n",
        "              0,\n",
        "              'random',\n",
        "              )"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a95xH_lICt0g"
      },
      "source": [
        "def eval(D,G_test,Ytest):\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        " \n",
        "\n",
        "  sdr_speech = SDR(s_est=speech_est,s=test_s)\n",
        "  sdr_music = SDR(s_est=music_est, s=test_m)\n",
        "  print(\"smr equal = {}\".format(SMR_db))\n",
        "\n",
        "  with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n",
        "  print(\"Speech SDR \\n\")\n",
        "  oc.myScript(speech_est ,test_s)\n",
        "  print(\"MUSIC SDR \\n\")\n",
        "  oc.myScript(music_est ,test_m)\n",
        "  #return speech_est,music_est"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vxkBgvYCmAs",
        "outputId": "0992acea-ef20-4707-ad04-383cb7b482f3"
      },
      "source": [
        "eval(np.transpose(B),G,Ytest)"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n",
            "smr equal = 0\n",
            "Speech SDR \n",
            "\n",
            "warning: function name 'bss_eval_sources' does not agree with function filename '/content/myScript.m'\n",
            "SDR =  4.8723\n",
            "warning: division by zero\n",
            "MUSIC SDR \n",
            "\n",
            "SDR =  3.9961\n",
            "warning: division by zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFuEl_CDOXX"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA1hcN94j7nd",
        "outputId": "fc857b1e-4fc2-48e5-d804-beda9d4e1f23"
      },
      "source": [
        "SMR_db = 0\n",
        "test,speech_test,music_test=get_mixed_signal(test_s,test_m,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ytest= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_test=np.abs(Ytest)\n",
        "\n",
        "Yabs_test[Yabs_test==0]=0.00001"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "za0jOM1lDOwA",
        "outputId": "a4a312f6-f639-4ede-f2b0-2acc85853dc1"
      },
      "source": [
        "Sources,Masks=Reconstruct(B=np.transpose(B),G=G,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "print('Reconstruction Step .... Done')\n",
        "speech_est = Sources[0]\n",
        "music_est = Sources[1]"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0PNgtTwDSkP"
      },
      "source": [
        "class DNN(nn.Module):\n",
        "\n",
        "    def __init__(self,d):\n",
        "        super(DNN, self).__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.fc1 = nn.Linear(d, 20,bias=False)  # d is dimension of the input.\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.Dropout(0.1)(self.relu(self.fc1(x)))\n",
        "\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGCLV-6xDp7C",
        "outputId": "dd5d1eba-4574-4570-8ef3-2651693064f4"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEM-O46wXU3X"
      },
      "source": [
        "\n",
        "model = DNN(20)\n",
        "b = torch.from_numpy(MinMaxScaler().fit_transform(B_mixed)).float()\n",
        "h = torch.from_numpy(G).float()\n",
        "y = torch.from_numpy(Yabs_test).float()\n",
        "\n",
        "#b = torch.tensor(B_t).to(device)\n",
        "#b = torch.tensor(B_t).to(device)\n"
      ],
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYO89WTEE2M5"
      },
      "source": [
        "def eval_dnn(D,G_test,Ytest):\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=10,Nm=10,Yabs=Ytest,p=1)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n",
        "  print(\"DNN Results \\n\")\n",
        "  print(\"Speech SDR \\n\")\n",
        "  oc.myScript(speech_est ,test_s)\n",
        "  print(\"MUSIC SDR \\n\")\n",
        "  oc.myScript(music_est ,test_m)\n",
        "\n",
        "def train_model(train,\n",
        "                y,\n",
        "                h,\n",
        "                model,\n",
        "                learning_rate=0.001,\n",
        "                batch_size = 1,\n",
        "                num_epochs=50,\n",
        "                factor_scheduler = 0.8):\n",
        "  \n",
        "  print(\"begin....\")\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr =learning_rate)\n",
        "  \n",
        "  train_numpy = np.array(train,dtype=\"float32\")\n",
        "  train_y = np.array(np.transpose(y),dtype=\"float32\")\n",
        "  train_h= np.array(np.transpose(h),dtype=\"float32\")\n",
        "\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_numpy,batch_size = batch_size)\n",
        "  train_Y = torch.utils.data.DataLoader(train_y,batch_size = batch_size)\n",
        "  train_H = torch.utils.data.DataLoader(train_h,batch_size = batch_size)\n",
        "\n",
        "  train_hist = np.zeros(num_epochs)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                         min_lr = 1e-4,\n",
        "                                                         mode = 'min',\n",
        "                                                         factor=factor_scheduler,\n",
        "                                                         verbose=True\n",
        "                                                         ,patience=10)\n",
        "\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    for y,h in zip(train_Y,train_H):\n",
        "      optimizer.zero_grad()\n",
        "      reconstructed = model(train)\n",
        "\n",
        "      loss = torch.nn.MSELoss()(y.t(),reconstructed@h.t())\n",
        "      train_hist[e] = loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "    if e%10 == 0:\n",
        "      print(f'Epoch {e} train loss:{loss.item()}')\n",
        "    scheduler.step(e)\n",
        "  print(\"finish !\")\n",
        "  return model.eval(), train_hist"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hTSu5iOEOZy",
        "outputId": "2b28bf49-41cd-4efc-9f8c-3b2480865b0f"
      },
      "source": [
        "h.shape"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 10001])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ZURv8fFnsA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d714388-772a-4334-8220-71dc1e689f21"
      },
      "source": [
        "model = DNN(20)\n",
        "\n",
        "model,train_hist = train_model(b,y,h,\n",
        "                model,\n",
        "                learning_rate=0.1,\n",
        "                batch_size = 32,\n",
        "                num_epochs=100,\n",
        "                factor_scheduler = 0.5)\n",
        "a = model(b).detach().numpy()\n",
        "a[a ==0] = 0.00000000001\n",
        "eval(a ,G,Ytest) "
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin....\n",
            "Epoch 0 train loss:1478.933837890625\n",
            "Epoch 10 train loss:1275.54638671875\n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-02.\n",
            "Epoch 20 train loss:1165.4560546875\n",
            "Epoch    23: reducing learning rate of group 0 to 2.5000e-02.\n",
            "Epoch 30 train loss:1076.9796142578125\n",
            "Epoch    34: reducing learning rate of group 0 to 1.2500e-02.\n",
            "Epoch 40 train loss:1137.478515625\n",
            "Epoch    45: reducing learning rate of group 0 to 6.2500e-03.\n",
            "Epoch 50 train loss:1039.2509765625\n",
            "Epoch    56: reducing learning rate of group 0 to 3.1250e-03.\n",
            "Epoch 60 train loss:1138.400146484375\n",
            "Epoch    67: reducing learning rate of group 0 to 1.5625e-03.\n",
            "Epoch 70 train loss:1006.4871826171875\n",
            "Epoch    78: reducing learning rate of group 0 to 7.8125e-04.\n",
            "Epoch 80 train loss:1166.568359375\n",
            "Epoch    89: reducing learning rate of group 0 to 3.9063e-04.\n",
            "Epoch 90 train loss:1284.92724609375\n",
            "Epoch   100: reducing learning rate of group 0 to 1.9531e-04.\n",
            "finish !\n",
            "Reconstruction Step .... Done\n",
            "smr equal = 0\n",
            "Speech SDR \n",
            "\n",
            "warning: function name 'bss_eval_sources' does not agree with function filename '/content/myScript.m'\n",
            "SDR =  5.2040\n",
            "warning: division by zero\n",
            "MUSIC SDR \n",
            "\n",
            "SDR =  4.0021\n",
            "warning: division by zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx7nRStjxugx"
      },
      "source": [
        "torch.save(model,\"model_smr_0\")"
      ],
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxivBvojK8te"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}