{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_gain_NMF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mc8NsZqwwWiQ",
        "outputId": "acad5dad-15df-4ae1-c0e2-16eeb8e7283f"
      },
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive # import drive from google colab\n",
        " \n",
        "ROOT = \"/content/drive\"     # default location for the drive\n",
        "print(ROOT)                 # print content of ROOT (Optional)\n",
        " \n",
        "drive.mount(ROOT)           # we mount the google drive at /content/drive\n",
        "from scipy import signal\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import inv\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as I\n",
        "from torch.nn import Sigmoid\n",
        "from torch import transpose\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLvpBa0ZwyQy"
      },
      "source": [
        "## This Notebook Gave in SMR=0 SDR=2.57 and 2.45"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bpxizni9Jyv"
      },
      "source": [
        "#!apt install octave\n",
        "#!apt install liboctave-dev  # development files\n",
        "#!pip3 install oct2py\n",
        "from oct2py import Oct2Py\n",
        "oc = Oct2Py()\n",
        "script = '''\n",
        "  function [SDR,SIR,SAR,perm]=bss_eval_sources(se,s)\n",
        "%%% Errors %%%\n",
        "if nargin<2, error('Not enough input arguments.'); end\n",
        "[nsrc,nsampl]=size(se);\n",
        "[nsrc2,nsampl2]=size(s);\n",
        "if nsrc2~=nsrc, error('The number of estimated sources and reference sources must be equal.'); end\n",
        "if nsampl2~=nsampl, error('The estimated sources and reference sources must have the same duration.'); end\n",
        "\n",
        "%%% Performance criteria %%%\n",
        "% Computation of the criteria for all possible pair matches\n",
        "SDR=zeros(nsrc,nsrc);\n",
        "SIR=zeros(nsrc,nsrc);\n",
        "SAR=zeros(nsrc,nsrc);\n",
        "for jest=1:nsrc,\n",
        "    for jtrue=1:nsrc,\n",
        "        [s_true,e_spat,e_interf,e_artif]=bss_decomp_mtifilt(se(jest,:),s,jtrue,512);\n",
        "        [SDR(jest,jtrue),SIR(jest,jtrue),SAR(jest,jtrue)]=bss_source_crit(s_true,e_spat,e_interf,e_artif);\n",
        "    end\n",
        "end\n",
        "% Selection of the best ordering\n",
        "perm=perms(1:nsrc);\n",
        "nperm=size(perm,1);\n",
        "meanSIR=zeros(nperm,1);\n",
        "for p=1:nperm,\n",
        "    meanSIR(p)=mean(SIR((0:nsrc-1)*nsrc+perm(p,:)));\n",
        "end\n",
        "[meanSIR,popt]=max(meanSIR);\n",
        "perm=perm(popt,:).';\n",
        "SDR=SDR((0:nsrc-1).'*nsrc+perm);\n",
        "SIR=SIR((0:nsrc-1).'*nsrc+perm);\n",
        "SAR=SAR((0:nsrc-1).'*nsrc+perm);\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "function [s_true,e_spat,e_interf,e_artif]=bss_decomp_mtifilt(se,s,j,flen)\n",
        "\n",
        "if nargin<4, error('Not enough input arguments.'); end\n",
        "[nchan2,nsampl2]=size(se);\n",
        "[nsrc,nsampl,nchan]=size(s);\n",
        "if nchan2~=nchan, error('The number of channels of the true source images and the estimated source image must be equal.'); end\n",
        "if nsampl2~=nsampl, error('The duration of the true source images and the estimated source image must be equal.'); end\n",
        "\n",
        "%%% Decomposition %%%\n",
        "% True source image\n",
        "s_true=[reshape(s(j,:,:),nsampl,nchan).',zeros(nchan,flen-1)];\n",
        "% Spatial (or filtering) distortion\n",
        "e_spat=project(se,s(j,:,:),flen)-s_true;\n",
        "% Interference\n",
        "e_interf=project(se,s,flen)-s_true-e_spat;\n",
        "% Artifacts\n",
        "e_artif=[se,zeros(nchan,flen-1)]-s_true-e_spat-e_interf;\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "function sproj=project(se,s,flen)\n",
        "\n",
        "% SPROJ Least-squares projection of each channel of se on the subspace\n",
        "% spanned by delayed versions of the channels of s, with delays between 0\n",
        "% and flen-1\n",
        "\n",
        "[nsrc,nsampl,nchan]=size(s);\n",
        "s=reshape(permute(s,[3 1 2]),nchan*nsrc,nsampl);\n",
        "\n",
        "%%% Computing coefficients of least squares problem via FFT %%%\n",
        "% Zero padding and FFT of input data\n",
        "s=[s,zeros(nchan*nsrc,flen-1)];\n",
        "se=[se,zeros(nchan,flen-1)];\n",
        "fftlen=2^nextpow2(nsampl+flen-1);\n",
        "sf=fft(s,fftlen,2);\n",
        "sef=fft(se,fftlen,2);\n",
        "% Inner products between delayed versions of s\n",
        "G=zeros(nchan*nsrc*flen);\n",
        "for k1=0:nchan*nsrc-1,\n",
        "    for k2=0:k1,\n",
        "        ssf=sf(k1+1,:).*conj(sf(k2+1,:));\n",
        "        ssf=real(ifft(ssf));\n",
        "        ss=toeplitz(ssf([1 fftlen:-1:fftlen-flen+2]),ssf(1:flen));\n",
        "        G(k1*flen+1:k1*flen+flen,k2*flen+1:k2*flen+flen)=ss;\n",
        "        G(k2*flen+1:k2*flen+flen,k1*flen+1:k1*flen+flen)=ss.';\n",
        "    end\n",
        "end\n",
        "% Inner products between se and delayed versions of s\n",
        "D=zeros(nchan*nsrc*flen,nchan);\n",
        "for k=0:nchan*nsrc-1,\n",
        "    for i=1:nchan,\n",
        "        ssef=sf(k+1,:).*conj(sef(i,:));\n",
        "        ssef=real(ifft(ssef,[],2));\n",
        "        D(k*flen+1:k*flen+flen,i)=ssef(:,[1 fftlen:-1:fftlen-flen+2]).';\n",
        "    end\n",
        "end\n",
        "\n",
        "%%% Computing projection %%%\n",
        "% Distortion filters\n",
        "C=G\\D;\n",
        "C=reshape(C,flen,nchan*nsrc,nchan);\n",
        "% Filtering\n",
        "sproj=zeros(nchan,nsampl+flen-1);\n",
        "for k=1:nchan*nsrc,\n",
        "    for i=1:nchan,\n",
        "        sproj(i,:)=sproj(i,:)+fftfilt(C(:,k,i).',s(k,:));\n",
        "    end\n",
        "end\n",
        "\n",
        "return;\n",
        "\n",
        "\n",
        "\n",
        "function [SDR,SIR,SAR]=bss_source_crit(s_true,e_spat,e_interf,e_artif)\n",
        "\n",
        "\n",
        "if nargin<4, error('Not enough input arguments.'); end\n",
        "[nchant,nsamplt]=size(s_true);\n",
        "[nchans,nsampls]=size(e_spat);\n",
        "[nchani,nsampli]=size(e_interf);\n",
        "[nchana,nsampla]=size(e_artif);\n",
        "if ~((nchant==nchans)&&(nchant==nchani)&&(nchant==nchana)), error('All the components must have the same number of channels.'); end\n",
        "if ~((nsamplt==nsampls)&&(nsamplt==nsampli)&&(nsamplt==nsampla)), error('All the components must have the same duration.'); end\n",
        "\n",
        "%%% Energy ratios %%%\n",
        "s_filt=s_true+e_spat;\n",
        "% SDR\n",
        "SDR=10*log10(sum(sum(s_filt.^2))/sum(sum((e_interf+e_artif).^2)))\n",
        "% SIR\n",
        "SIR=10*log10(sum(sum(s_filt.^2))/sum(sum(e_interf.^2)));\n",
        "% SA\n",
        "SAR=10*log10(sum(sum((s_filt+e_interf).^2))/sum(sum(e_artif.^2)));\n",
        "return;\n",
        "\n",
        "         '''\n",
        "\n",
        "with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2r72nk9HrbY"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from numpy import linalg as LA\n",
        "\n",
        "def Viz_Y(t,f,Y, vmin=0, vmax=20):\n",
        "    plt.figure(figsize=(20,7))\n",
        "    plt.pcolormesh(t, f, Y,vmin=0, vmax=20, shading='gouraud')\n",
        "    plt.title('STFT Magnitude')\n",
        "    plt.ylabel('Frequency [Hz]')\n",
        "    plt.xlabel('Time [sec]')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def SMR(speech, music):\n",
        "    \n",
        "    \"\"\"\n",
        "    Function that takes music and speech signals.\n",
        "    returns SMR in db\n",
        "    \"\"\"\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    SMR_db=10*np.log10(speech_power/music_power)\n",
        "    print('SMR = {:.2f}'.format(SMR_db))\n",
        "    \n",
        "    return SMR_db\n",
        "\n",
        "def SDR(s_est, s):\n",
        "    \"\"\"\n",
        "    Function that takes original and estimated spectrogram\n",
        "    returns SDR in DB\n",
        "    \"\"\"\n",
        "    \n",
        "    signal_power = LA.norm(s,2)\n",
        "    distorsion_power = LA.norm(s_est - s,2) \n",
        "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
        "    \n",
        "    return SDR_db\n",
        "\n",
        "def plot_SDR(list_smr,list_music,list_speech):\n",
        "  plt.figure(figsize=(10,5))\n",
        "  sns.set_style(\"darkgrid\")\n",
        "\n",
        "  ax1 = sns.lineplot(list_smr,list_music)\n",
        "  ax2 = sns.lineplot(list_smr,list_speech)\n",
        "  ax1.set(xlabel='SMR  (db)', ylabel='SMR  (db)')\n",
        "  ax1.legend([\"Estimated MUSIC signal\",\"Estimated SPEECH signal\"])\n",
        "  plt.show()\n",
        "  \n",
        "def get_mixed_signal(speech, music, SMR_db):\n",
        "    \"\"\"\n",
        "    Function taht takes the speech and music signal alongside the SMR_db\n",
        "    returns the mixed signal and the scaled speech\n",
        "    \"\"\"\n",
        "    smr = 10**(SMR_db/10)\n",
        "    speech_power = LA.norm(speech,2)\n",
        "    music_power = LA.norm(music,2)\n",
        "    scale = smr * music_power / speech_power\n",
        "    \n",
        "\n",
        "    \n",
        "    if SMR_db < 0 :\n",
        "        mixed = scale* speech + music\n",
        "        music_scaled=(1/scale)*music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "    \n",
        "    if SMR_db >= 0 :\n",
        "        \n",
        "        mixed =  speech + music * (1/scale)\n",
        "        music_scaled=(1/scale) * music\n",
        "        SMR(speech,music_scaled)\n",
        "        return mixed,speech,music_scaled\n",
        "\n",
        "\n",
        "def load_data(path_music,path_speech,sec):\n",
        "\n",
        "  samplerate_m,music = read(path_music)\n",
        "  music=music[:44100*sec,0]\n",
        "  length=music.shape[0]/samplerate_m\n",
        "  print('Shape of the music {}'.format(music.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_m))\n",
        "\n",
        "\n",
        "  samplerate_s,speech = read(path_speech)\n",
        "  speech=speech[:44100*sec,0]\n",
        "\n",
        "  length=speech.shape[0]/samplerate_s\n",
        "  print('Shape of the speech {}'.format(speech.shape[0]))\n",
        "  print('Length : {:.2f}s'.format(length))\n",
        "  print('Sample rate : {}'.format(samplerate_s))\n",
        "\n",
        "  return music,speech,samplerate_s\n",
        "\n",
        "  \n",
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def speech_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G,model.reconstruction_err_\n",
        "def music_nmf(Y,n_component,max_iter,a,initt):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init=initt,\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G, model.reconstruction_err_\n",
        "\n",
        "\n",
        "\n",
        "def training(Yabs_music,\n",
        "               Yabs_speech,\n",
        "               init,\n",
        "               s_component = 128,\n",
        "               m_component = 128,\n",
        "               iterations = 200,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2,\n",
        "             samplerate=16000,\n",
        "                ):\n",
        "  ###################################   STFT   #######################################\n",
        "  S_abs = Yabs_speech\n",
        "  M_abs = Yabs_music\n",
        "  print(\"Training Stage ....\")\n",
        "  B_speech,_,error_speech = speech_nmf(S_abs,s_component,iterations,s_alpha,initt=init)\n",
        "  B_music,_,error_music =   music_nmf(M_abs,m_component,iterations,m_alpha,initt=init)\n",
        "  print(\"Training finish ! ....\")\n",
        "  #####################################################################################\n",
        "  B_mixed = np.concatenate([B_speech,B_music],axis = 1)                                # Concatenation of both  training dictionnaries\n",
        "  print(\"SPEECH reconstruction Loss {}\".format(error_speech))\n",
        "  print(\"MUSIC reconstruction Loss {}\".format(error_music))\n",
        "\n",
        "  return B_mixed\n",
        "def eval(D,G_test,Ytest):\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=8,Nm=8,Yabs=Ytest,p=1)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        " \n",
        "\n",
        "  sdr_speech = SDR(s_est=speech_est,s=test_s)\n",
        "  sdr_music = SDR(s_est=music_est, s=test_m)\n",
        "  print(\"smr equal = {}\".format(SMR_db))\n",
        "\n",
        "  with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n",
        "  print(\"Speech SDR \\n\")\n",
        "  oc.myScript(speech_est ,test_s)\n",
        "  print(\"MUSIC SDR \\n\")\n",
        "  oc.myScript(music_est ,test_m)\n",
        "  #return speech_est,music_est\n"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idEcwxGxxkOd",
        "outputId": "6b2e7fc7-0d10-46d3-d216-7ec78dad152d"
      },
      "source": [
        "# Best 1-20 min\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100 \n",
        "\n",
        "samplerate_s, data_speech = read(\"/content/drive/MyDrive/Conversation.wav\")\n",
        "speech=data_speech[start:end,0]\n",
        "length=speech.shape[0]/samplerate_s\n",
        "print('Shape of the speech {} ... Length : {:.2f}s ... Sample rate : {}'.format(speech.shape[0],length,samplerate_s))\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100 \n",
        "samplerate_m, data_music = read(\"/content/drive/MyDrive/music.wav\")\n",
        "music=data_music[start:end,0]\n",
        "length=music.shape[0]/samplerate_m\n",
        "print('Shape of the music {} ... Length : {:.2f}s ... Sample rate : {}'.format(music.shape[0],length,samplerate_m))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the speech 50274000 ... Length : 1140.00s ... Sample rate : 44100\n",
            "Shape of the music 50274000 ... Length : 1140.00s ... Sample rate : 44100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMZEZdLJxo15",
        "outputId": "e8a61ef6-dacb-4cf2-9341-5aace32ba4f1"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = 1 * 60 * 44100\n",
        "end = 20 * 60 * 44100\n",
        "\n",
        "\n",
        "speech_t=data_speech[start : end, 0]\n",
        "music_t = data_music[start : end, 0]\n",
        "\n",
        "\n",
        "speech_t = signal.resample(speech_t,int(speech_t.shape[0]/rate))\n",
        "music_t = signal.resample(music_t,int(music_t.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "print('Shape of the test {} ... Length : {:.2f}s ... Sample rate : {}'.format(music_t.shape[0],length,samplerate))\n",
        "\n",
        "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
        "music = signal.resample(music,int(music.shape[0]/rate))\n",
        "\n",
        "\n",
        "print('Downsampled rate = {}'.format(samplerate))\n",
        "\n",
        "speech = butter_lowpass_filter(speech,5000,fs)\n",
        "music = butter_lowpass_filter(music,5000,fs)\n",
        "\n",
        "music_t = butter_lowpass_filter(music_t,5000,fs)\n",
        "speech_t = butter_lowpass_filter(speech_t,5000,fs)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the test 18240000 ... Length : 1140.00s ... Sample rate : 16000\n",
            "Downsampled rate = 16000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbke3Fm4zEG5"
      },
      "source": [
        "## Training STFT :\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHbUgVOAyDiz",
        "outputId": "ee83edaa-4176-4a86-e711-dfcae1325f33"
      },
      "source": [
        "WINDOW = 'hamming'\n",
        "WINDOW_SIZE=480\n",
        "OVERLAP = 0.8 * WINDOW_SIZE\n",
        "NFFT=512\n",
        "\n",
        "f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_speech=np.abs(Y)\n",
        "f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_music=np.abs(Y)\n",
        "\n",
        "\n",
        "\n",
        "SMR_db = 5\n",
        "mix,speech_mix,music_mix=get_mixed_signal(speech_t,music_t,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ymix= signal.stft(mix,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_mix=np.abs(Ymix)\n",
        "\n",
        "Yabs_mix[Yabs_mix==0]=0.00001\n",
        "#write(\"/MixX.wav\", samplerate, mix.astype(np.int16))\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = 5.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTyG9UYBzIto"
      },
      "source": [
        "## Test STFT :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa1jCmT4yHq_",
        "outputId": "ac86a589-d4d9-42e9-b03f-8c5ec9296926"
      },
      "source": [
        "fs = 16000\n",
        "\n",
        "rate = samplerate_s / fs\n",
        "\n",
        "\n",
        "start = int(20 * 60 * 44100)\n",
        "step = int(0.5 * 60 * 44100)\n",
        "\n",
        "test_s = np.array([])\n",
        "test_m = np.array([])\n",
        "\n",
        "for i in range(1):\n",
        "\n",
        "  test_s = np.hstack([test_s,data_speech[start+i*step:start+(i+1)*step,0]])\n",
        "  test_m = np.hstack([test_m,data_music[start+i*step:start+(i+1)*step,0]])\n",
        "\n",
        "\n",
        "test_s = signal.resample(test_s,int(test_s.shape[0]/rate))\n",
        "test_m = signal.resample(test_m,int(test_m.shape[0]/rate))\n",
        "samplerate=int(samplerate_m/rate)\n",
        "length=music_t.shape[0]/samplerate\n",
        "\n",
        "\n",
        "test_s = butter_lowpass_filter(test_s,5000,fs)\n",
        "test_m = butter_lowpass_filter(test_m,5000,fs)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "SMR_db = 0\n",
        "test,speech_test,music_test=get_mixed_signal(test_s,test_m,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ytest= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_test=np.abs(Ytest)\n",
        "\n",
        "Yabs_test[Yabs_test==0]=0.00001\n"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjWdkHsOdDZ6"
      },
      "source": [
        "# Train First NMF on Clean Speech :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohqeS3S86_Nw"
      },
      "source": [
        "def softmax(x):\n",
        "\n",
        "  e_x = np.exp(x)\n",
        "  return e_x / e_x.sum(axis=0)"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NWob8QfJ6_q"
      },
      "source": [
        "def mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              iterations,\n",
        "              a=100,\n",
        "              initt=\"nndsvd\",\n",
        "              ):\n",
        "  n_components=B_mixed.shape[1]\n",
        "  model = NMF(n_components=n_components,\n",
        "              init=initt,\n",
        "              alpha=a,\n",
        "              beta_loss='itakura-saito',\n",
        "              solver=\"mu\",\n",
        "              max_iter=iterations,\n",
        "              random_state=7)\n",
        "  \n",
        "  model.fit(np.transpose(Yabs_test))\n",
        "\n",
        "  model.components_ = np.transpose(B_mixed)\n",
        "\n",
        "  G0 = model.transform(np.transpose(Yabs_test))\n",
        "\n",
        "  return np.transpose(G0),model.reconstruction_err_,model.components_\n",
        "\n",
        "def validation(B_mixed,\n",
        "               speech,\n",
        "               music,\n",
        "               s_component,\n",
        "               m_component,\n",
        "               alpha,\n",
        "               init,\n",
        "               smr,\n",
        "               iterations,\n",
        "               samplerate=16000\n",
        "               ):\n",
        "\n",
        "\n",
        "  G_mixed,reconstruction,update_or_not = mixed_nmf(B_mixed,\n",
        "              mixed_abs,\n",
        "              iterations,\n",
        "              alpha,\n",
        "              init\n",
        "              )\n",
        "  return B_mixed, G_mixed"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXYfL9S6CALT"
      },
      "source": [
        "B_mixed = np.load(\"/content/drive/MyDrive/B.npy\")\n",
        "G,_,B = mixed_nmf(B_mixed,\n",
        "              Yabs_test,\n",
        "              100,\n",
        "              100,\n",
        "              'random',\n",
        "              )"
      ],
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GmZsT1dYwSS",
        "outputId": "2b7a3d0c-71e9-4127-d584-707565740e8b"
      },
      "source": [
        "eval(np.transpose(B),G,Ytest) "
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reconstruction Step .... Done\n",
            "smr equal = 0\n",
            "Speech SDR \n",
            "\n",
            "warning: function name 'bss_eval_sources' does not agree with function filename '/content/myScript.m'\n",
            "SDR =  3.8036\n",
            "warning: division by zero\n",
            "MUSIC SDR \n",
            "\n",
            "SDR =  3.4576\n",
            "warning: division by zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zFuEl_CDOXX"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA1hcN94j7nd",
        "outputId": "9cdfcc1d-79fe-43f4-fac3-6aa5f723415a"
      },
      "source": [
        "SMR_db = 0\n",
        "test,speech_test,music_test=get_mixed_signal(test_s,test_m,SMR_db)\n",
        "\n",
        "\n",
        "f,t,Ytest= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "Yabs_test=np.abs(Ytest)\n",
        "\n",
        "Yabs_test[Yabs_test==0]=0.00001"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = -0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0PNgtTwDSkP"
      },
      "source": [
        "class DNN(nn.Module):\n",
        "\n",
        "    def __init__(self,d):\n",
        "        super(DNN, self).__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.leaky_relu = torch.nn.LeakyReLU()\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "        self.fc1 = nn.Linear(d, 10,bias=True)  # d is dimension of the input.\n",
        "        self.fc2 = nn.Linear(10, 5,bias=True)  # d is dimension of the input.\n",
        "        self.fc3 = nn.Linear(5, 10,bias=True)  # d is dimension of the input.\n",
        "        self.fc4 = nn.Linear(10, d,bias=True)  # d is dimension of the input.\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.Dropout(0.1)(self.relu(self.fc1(x)))\n",
        "        x = torch.nn.Dropout(0)(self.relu(self.fc2(x)))\n",
        "        x = torch.nn.Dropout(0)(self.relu(self.fc3(x)))\n",
        "        x = torch.nn.Dropout(0)(self.relu(self.fc4(x)))\n",
        "\n",
        "\n",
        "\n",
        "        return x"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGCLV-6xDp7C",
        "outputId": "85ce7492-3327-418d-ac13-35ccb8b7b9d1"
      },
      "source": [
        "print(torch.cuda.is_available())\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEM-O46wXU3X"
      },
      "source": [
        "\n",
        "model = DNN(16)\n",
        "b = torch.from_numpy(B_mixed).float()\n",
        "h = torch.from_numpy(MinMaxScaler().fit_transform(G)).float()\n",
        "y = torch.from_numpy(Yabs_test).float()"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UljfHh7OvB5g"
      },
      "source": [
        "\n",
        "def train_weights(train,\n",
        "                y,\n",
        "                h,\n",
        "                model,\n",
        "                learning_rate=0.001,\n",
        "                batch_size = 1,\n",
        "                num_epochs=50,\n",
        "                factor_scheduler = 0.8):\n",
        "  \n",
        "  print(\"begin....\")\n",
        "  \n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr =learning_rate)\n",
        "  \n",
        "  train_numpy = np.array(train,dtype=\"float32\")\n",
        "  train_y = np.array(np.transpose(y),dtype=\"float32\")\n",
        "  train_h= np.array(np.transpose(h),dtype=\"float32\")\n",
        "  e = 0.000000001\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_numpy,batch_size = batch_size)\n",
        "  train_Y = torch.utils.data.DataLoader(train_y,batch_size = batch_size)\n",
        "  train_H = torch.utils.data.DataLoader(train_h,batch_size = batch_size)\n",
        "\n",
        "  train_hist = np.zeros(num_epochs)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                         min_lr = 1e-5,\n",
        "                                                         mode = 'min',\n",
        "                                                         factor=factor_scheduler,\n",
        "                                                         verbose=True\n",
        "                                                         ,patience=10)\n",
        "\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    for h_ in train_H:\n",
        "      optimizer.zero_grad()\n",
        "      reconstructed = model(h_)\n",
        "      loss = torch.nn.MSELoss()(h_,reconstructed)\n",
        "      train_hist[e] = loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "    if e%20 == 0:\n",
        "      print(f'Epoch {e} train loss:{loss.item()}')\n",
        "  print(\"finish !\")\n",
        "\n",
        "  return model.eval(), train_hist\n",
        "  \n",
        "model = DNN(16)\n",
        "\n",
        "pre_model,train_hist = train_weights(b,y,h,\n",
        "                model,\n",
        "                learning_rate = 0.1,\n",
        "                batch_size = 3,\n",
        "                num_epochs = 200,\n",
        "                factor_scheduler = 0.8)\n",
        "                \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GNh_-Px1UKO"
      },
      "source": [
        "model.load_state_dict(pre_model.state_dict())\n",
        "torch.save(model,\"ae_pretrained_sgd\")"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYO89WTEE2M5"
      },
      "source": [
        "def eval_dnn(D,G_test,Ytest,p):\n",
        "  d = p\n",
        "  Sources,Masks=Reconstruct(B=D,G=G_test,Ns=8,Nm=8,Yabs=Ytest,p=d)\n",
        "\n",
        "  print('Reconstruction Step .... Done')\n",
        "  speech_est = Sources[0]\n",
        "  music_est = Sources[1]\n",
        "\n",
        "  _, speech_est =  signal.istft(speech_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  _, music_est =  signal.istft(music_est,\n",
        "                      samplerate,\n",
        "                      window = WINDOW,\n",
        "                      nperseg=WINDOW_SIZE,\n",
        "                      noverlap=OVERLAP,\n",
        "                      nfft = NFFT)\n",
        "\n",
        "  with open(\"myScript.m\",\"w+\") as f:\n",
        "    f.write(script)\n",
        "  print(\"DNN Results \\n\")\n",
        "  print(\"Speech SDR \\n\")\n",
        "  oc.myScript(speech_est ,test_s)\n",
        "  print(\"MUSIC SDR \\n\")\n",
        "  oc.myScript(music_est ,test_m)\n",
        "def KL_divergence(x, y):\n",
        "    return x*torch.log(x / y) \n",
        "def train_model(train,\n",
        "                y,\n",
        "                h,\n",
        "                model,\n",
        "                learning_rate=0.001,\n",
        "                batch_size = 1,\n",
        "                num_epochs=50,\n",
        "                factor_scheduler = 0.8):\n",
        "  \n",
        "  print(\"begin....\")\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr =learning_rate)\n",
        "  \n",
        "  train_numpy = np.array(train,dtype=\"float32\")\n",
        "  train_y = np.array(np.transpose(y),dtype=\"float32\")\n",
        "  train_h= np.array(np.transpose(h),dtype=\"float32\")\n",
        "  e = 0.000000001\n",
        "\n",
        "  trainloader = torch.utils.data.DataLoader(train_numpy,batch_size = batch_size)\n",
        "  train_Y = torch.utils.data.DataLoader(train_y,batch_size = batch_size)\n",
        "  train_H = torch.utils.data.DataLoader(train_h,batch_size = batch_size)\n",
        "\n",
        "  train_hist = np.zeros(num_epochs)\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                         min_lr = 1e-5,\n",
        "                                                         mode = 'min',\n",
        "                                                         factor=factor_scheduler,\n",
        "                                                         verbose=True\n",
        "                                                         ,patience=10)\n",
        "\n",
        "\n",
        "  for e in range(num_epochs):\n",
        "    for y,h_ in zip(train_Y,train_H):\n",
        "      optimizer.zero_grad()\n",
        "      reconstructed = model(h_)\n",
        "      loss = torch.nn.MSELoss()(y.t(),train@reconstructed.t())\n",
        "     # loss += 0.001*torch.sum(KL_divergence(y.t() + e, train@reconstructed.t()+ e)) \n",
        "      #loss += 0.1*torch.nn.MSELoss()(train,reconstructed)\n",
        "      train_hist[e] = loss.item()\n",
        "      #loss += 100*torch.sum(reconstructed)\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "      \n",
        "    if e%20 == 0:\n",
        "      print(f'Epoch {e} train loss:{loss.item()}')\n",
        "      a = model(h.t()).t().detach().numpy()\n",
        "      a[a == 0] = 0.00000000001\n",
        "      eval_dnn(np.transpose(B) ,a,Ytest,p=3) \n",
        "    scheduler.step(e)\n",
        "  print(\"finish !\")\n",
        "\n",
        "  return model.eval(), train_hist\n",
        "  "
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CNLlwUIxw48",
        "outputId": "2021fe0a-f436-4d08-a9e8-f45aaa649cdb"
      },
      "source": [
        "model = DNN(16)\n",
        "model.load_state_dict(pre_model.state_dict())"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "oUQHY2M4rcjy",
        "outputId": "3196f3d4-0e67-4182-9b32-3bd756328e4a"
      },
      "source": [
        "model,train_hist = train_model(b,y,h,\n",
        "                model,\n",
        "                learning_rate = 0.0001,\n",
        "                batch_size = 32,\n",
        "                num_epochs = 100,\n",
        "                factor_scheduler = 0.5)"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin....\n",
            "Epoch 0 train loss:6861.49951171875\n",
            "Reconstruction Step .... Done\n",
            "DNN Results \n",
            "\n",
            "Speech SDR \n",
            "\n",
            "warning: function name 'bss_eval_sources' does not agree with function filename '/content/myScript.m'\n",
            "SDR =  4.6365\n",
            "warning: division by zero\n",
            "MUSIC SDR \n",
            "\n",
            "SDR =  3.9416\n",
            "warning: division by zero\n",
            "Epoch    12: reducing learning rate of group 0 to 5.0000e-05.\n",
            "Epoch 20 train loss:7142.6171875\n",
            "Reconstruction Step .... Done\n",
            "DNN Results \n",
            "\n",
            "Speech SDR \n",
            "\n",
            "warning: function name 'bss_eval_sources' does not agree with function filename '/content/myScript.m'\n",
            "SDR =  5.8594\n",
            "warning: division by zero\n",
            "MUSIC SDR \n",
            "\n",
            "SDR =  4.4968\n",
            "warning: division by zero\n",
            "Epoch    23: reducing learning rate of group 0 to 2.5000e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-260-2334010c335b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 factor_scheduler = 0.5)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-254-d6bea6195a89>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train, y, h, model, learning_rate, batch_size, num_epochs, factor_scheduler)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_H\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m      \u001b[0;31m# loss += 0.001*torch.sum(KL_divergence(y.t() + e, train@reconstructed.t()+ e))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-235-bee453527216>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg55J8tnzlAG"
      },
      "source": [
        "torch.save(model,\"ae_pretrained_sgd3_300\")"
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "TEzoy7ol4POD",
        "outputId": "9db2aa2d-dee7-4f79-b1f7-ae19f242575b"
      },
      "source": [
        "a = model(h.t()).t().detach().numpy()\n",
        "a[a == 0] = 0.00000000001\n",
        "eval_dnn(np.transpose(B) ,a,Ytest,p=3) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-74458faecf41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00000000001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_dnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mYtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30xNB78m432h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}