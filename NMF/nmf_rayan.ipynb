{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmf_rayan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "shgQ2hvdBkLT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io.wavfile import read, write\n",
        "from scipy import signal\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from numpy.linalg import inv\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as I\n",
        "from torch.nn import Sigmoid\n",
        "\n",
        "from torch import transpose\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import numpy as np\n",
        "from scipy.signal import butter, lfilter, freqz\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uF86xdXcKGn6",
        "outputId": "24f8380f-132e-4935-b581-8f2de12fbdf6"
      },
      "source": [
        "from helpers import *\n",
        "#from nmf_utils import *\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7V2YeAGBkLY"
      },
      "source": [
        "# Apply STFT :\n",
        "\n",
        "## We can change :\n",
        "\n",
        "* Window : Type of window\n",
        "* nperseg : length of window\n",
        "* noverlap : overlap between windows.\n",
        "* nfft : fft length > window size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbdrXIYx9tNS"
      },
      "source": [
        "!ffmpeg -i  \"/content/drive/MyDrive/vocal_10.mp3\" \"vocal.wav\"\n",
        "!ffmpeg -i  \"/content/drive/MyDrive/piano_10.mp3\" \"music.wav\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2n3wa8lFNPMk",
        "outputId": "cc09f9a9-f53c-47ec-be56-100f0f0953f4"
      },
      "source": [
        "\n",
        "samplerate_m,music = read(\"music.wav\")\n",
        "music=music[:44100*1088,0]\n",
        "length=music.shape[0]/samplerate_m\n",
        "print('Shape of the music {}'.format(music.shape[0]))\n",
        "print('Length : {:.2f}s'.format(length))\n",
        "print('Sample rate : {}'.format(samplerate_m))\n",
        "\n",
        "\n",
        "samplerate_s,speech = read(\"vocal.wav\")\n",
        "speech=speech[:44100*1088,0]\n",
        "#speech = butter_lowpass_filter(speech,5000,44100)\n",
        "\n",
        "length=speech.shape[0]/samplerate_s\n",
        "print('Shape of the speech {}'.format(speech.shape[0]))\n",
        "print('Length : {:.2f}s'.format(length))\n",
        "print('Sample rate : {}'.format(samplerate_s))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the music 47980800\n",
            "Length : 1088.00s\n",
            "Sample rate : 44100\n",
            "Shape of the speech 47980800\n",
            "Length : 1088.00s\n",
            "Sample rate : 44100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O44S8pVAkIpF"
      },
      "source": [
        "## Low band Filter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Ur8WqQkKpq"
      },
      "source": [
        "def butter_lowpass(cutoff, fs, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return b, a\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
        "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
        "    y = lfilter(b, a, data)\n",
        "    return y\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bANhN9RjSgFA"
      },
      "source": [
        "## Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2EUU-uGSp0H"
      },
      "source": [
        "from scipy import signal"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dySIXiXiShvO"
      },
      "source": [
        "rate = 44100/16000\n",
        "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
        "music=signal.resample(music,int(music.shape[0]/rate))\n",
        "samplerate_m=int(samplerate_m/rate)\n",
        "samplerate_s=samplerate_m\n",
        "samplerate_t=samplerate_m"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoLZWdzPpTyK",
        "outputId": "5a2c1820-e847-48cb-a110-61d12675e48a"
      },
      "source": [
        "samplerate_t"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIWUBgjL_Ld5"
      },
      "source": [
        "# Train / Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22-K9aJ3_NWd"
      },
      "source": [
        "train_speech   = np.concatenate([speech[samplerate_t*60:samplerate_t*440],speech[samplerate_t*600:samplerate_t*900]],axis=0)\n",
        "train_music    = np.concatenate([music[samplerate_t*60:samplerate_t*440],music[samplerate_t*600:samplerate_t*900]],axis=0)\n",
        "\n",
        "test_speech ,  test_music =  speech[samplerate_t*440:samplerate_t*470]  , music[samplerate_t*440:samplerate_t*470]\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el-iw9LrXFdG",
        "outputId": "224f3f73-b17d-4f83-9736-23eadb316c94"
      },
      "source": [
        "SMR(train_speech,train_music)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMR = 2.99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.9862609974580523"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4DsXU_cUZmw"
      },
      "source": [
        "#from helpers import *\n",
        "\n",
        "def speech_nmf(Y,n_component,max_iter,a):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init='random',\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G, model.reconstruction_err_\n",
        "def music_nmf(Y,n_component,max_iter,a):\n",
        "\n",
        "\n",
        "  Y[Y==0]=0.0001\n",
        "  model = NMF(n_components=n_component,\n",
        "            init='random',\n",
        "            alpha=a,\n",
        "            beta_loss='itakura-saito',\n",
        "            solver=\"mu\",\n",
        "            max_iter=max_iter,\n",
        "            random_state=0)\n",
        "  B = model.fit_transform(Y)\n",
        "  G = model.components_\n",
        "  return B,G, model.reconstruction_err_\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez8o7J3uqBqK"
      },
      "source": [
        "def Reconstruct(B,G,Ns,Nm,Yabs,p):\n",
        "    \n",
        "    numerators=[]\n",
        "    B1=B[:,:Ns]\n",
        "    B2=B[:,Ns:]\n",
        "    G1=G[:Ns,:]\n",
        "    G2=G[Ns:,:]\n",
        "    \n",
        "    \n",
        "    numerators.append(np.power(np.matmul(B1,G1),p))\n",
        "    numerators.append(np.power(np.matmul(B2,G2),p))\n",
        "\n",
        "    denominator = np.power(np.matmul(B1,G1),p)+np.power(np.matmul(B2,G2),p)\n",
        "  \n",
        "    \n",
        "\n",
        "    Sources=[]\n",
        "    Masks=[]\n",
        "    for i in range(2):\n",
        "\n",
        "        Sources.append(np.multiply(numerators[i]/denominator,Yabs))\n",
        "        Masks.append(numerators[i]/denominator)\n",
        "\n",
        "    #print('Source shape = {}'.format(Sources[0].shape))\n",
        "    \n",
        "    return Sources,Masks\n",
        "def training(music_s,\n",
        "               speech_s,\n",
        "               s_component = 128,\n",
        "               m_component = 128,\n",
        "               iterations = 200,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2,\n",
        "             samplerate=16000,\n",
        "                ):\n",
        "  ###################################   STFT   #######################################\n",
        "  WINDOW = 'hamming'\n",
        "  WINDOW_SIZE=480\n",
        "  OVERLAP = 0.6 * WINDOW_SIZE\n",
        "  NFFT=512\n",
        "  #_,speech_s,music_s = get_mixed_signal(spe)\n",
        "\n",
        "  f,t,M= signal.stft(music_s,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)    # spectrum  of music signal\n",
        "\n",
        "  f,t,S= signal.stft(speech_s,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)   # spectrum  of speech signal\n",
        "\n",
        "  #####################################################################################\n",
        "\n",
        "\n",
        "  ## Magnitude of each spectrum source \n",
        "\n",
        "  M_abs=np.abs(M)\n",
        "\n",
        "  S_abs=np.abs(S)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ##############################   NMF Training   #####################################\n",
        "  print(\"Training Stage ....\")\n",
        "  B_speech,_,error_speech = speech_nmf(S_abs,s_component,iterations,s_alpha)\n",
        "  B_music,_,error_music =   music_nmf(M_abs,m_component,iterations,m_alpha)\n",
        "  print(\"Training finish ! ....\")\n",
        "\n",
        "  #####################################################################################\n",
        "\n",
        "  B_mixed = np.concatenate([B_speech,B_music],axis = 1)                                # Concatenation of both  training dictionnaries\n",
        "  print(\"SPEECH reconstruction Loss {}\".format(error_speech))\n",
        "  print(\"MUSIC reconstruction Loss {}\".format(error_music))\n",
        "\n",
        "  return B_mixed"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeS10T-vfplV"
      },
      "source": [
        "def mixed_nmf(B_mixed,\n",
        "              Y_test,\n",
        "              iterations,\n",
        "              a\n",
        "              ):\n",
        "  n_components=B_mixed.shape[1]\n",
        "  model = NMF(n_components=n_components,\n",
        "              init='random',\n",
        "              alpha=a,\n",
        "              beta_loss='itakura-saito',\n",
        "              solver=\"mu\",\n",
        "              max_iter=iterations,\n",
        "              random_state=0)\n",
        "  \n",
        "  model.fit(np.transpose(Y_test))\n",
        "\n",
        "  model.components_ = np.transpose(B_mixed)\n",
        "\n",
        "  G0 = model.transform(np.transpose(Y_test))\n",
        "\n",
        "  return np.transpose(G0),model.reconstruction_err_,model.components_"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0xOEEzlJbHn"
      },
      "source": [
        "def validation(B_mixed,\n",
        "               speech,\n",
        "               music,\n",
        "               s_component,\n",
        "               m_component,\n",
        "               smr,\n",
        "               iterations,\n",
        "               samplerate=16000\n",
        "               ):\n",
        "\n",
        "  mixed_signal , speech_signal, music_signal = get_mixed_signal(speech,music,smr)\n",
        "  #mixed_signal = mixed_signal\n",
        "  WINDOW = 'hamming'\n",
        "  WINDOW_SIZE=480\n",
        "  OVERLAP = 0.6 * WINDOW_SIZE\n",
        "  NFFT=512\n",
        "\n",
        "  f,t,mixed_spectrum = signal.stft(mixed_signal,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT) # spectrum  of mixed signal\n",
        "\n",
        "  mixed_abs = np.abs(mixed_spectrum)\n",
        "  G_mixed,reconstruction,update_or_not = mixed_nmf(B_mixed,\n",
        "              mixed_abs,\n",
        "              iterations,\n",
        "              0\n",
        "              )\n",
        "  #B_mixed,G_mixed,error_speech = speech_nmf(mixed_abs,s_component,iterations,0)\n",
        "  print(\"ok\")\n",
        "  sources,masks = Reconstruct(B_mixed,\n",
        "                              G_mixed,\n",
        "                              s_component,\n",
        "                              m_component,\n",
        "                              mixed_spectrum,\n",
        "                              2)\n",
        "  _, speech_estimate =  signal.istft( sources[0],samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "  _, music_estimate =    signal.istft(sources[1],samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
        "  print(\"Separation finish ! ....\")\n",
        "  #print(speech_estimate.shape, speech.shape)\n",
        "  sdr_speech = SDR(speech_estimate[:speech_signal.shape[0]],speech_signal)\n",
        "  \n",
        "  sdr_music = SDR(music_estimate[:music_signal.shape[0]],music_signal)\n",
        "  print(\"Evaluation .....\")\n",
        "  #print(update_or_not)\n",
        "  print(\"SMR ={} N_components ={}: \\nSDR Speech = {}\\nSDR Music  = {}\".format(smr,s_component,sdr_speech,sdr_music))\n",
        "  print(reconstruction)\n",
        "\n",
        "  write(\"Speech{}.wav\".format(iterations), samplerate, speech_estimate.astype(np.int16))\n",
        "  write(\"Music.wav\".format(iterations), samplerate, music_estimate.astype(np.int16))\n",
        "  return smr,sdr_speech,sdr_music,update_or_not"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6852M_ay2UN",
        "outputId": "eca5df46-8d5f-42fa-9b5a-0bff638206f5"
      },
      "source": [
        "B_all_list_2= []\n",
        "for c in [2]:\n",
        "  B_mixed = training(train_music,\n",
        "               train_speech,\n",
        "               s_component = c,\n",
        "               m_component = c,\n",
        "               iterations = 100,\n",
        "               s_alpha = 0,\n",
        "               m_alpha = 0,\n",
        "               p = 2)\n",
        "  B_mixed_new = MinMaxScaler().fit_transform(B_mixed)\n",
        "  B_all_list_2.append(B_mixed_new)\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Stage ....\n",
            "Training finish ! ....\n",
            "SPEECH reconstruction Loss 4462.14015906347\n",
            "MUSIC reconstruction Loss 3140.7534270949936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ5UMJgMwHdq",
        "outputId": "dfe85c23-3315-4423-8521-5405ce25ba0d"
      },
      "source": [
        "for it in [1,10,100]:\n",
        "  for i in range(len(B_all_list_2)):\n",
        "    Q = np.int(B_all_list_2[i].shape[1] / 2 )\n",
        "    for s in [0]:\n",
        "      a,x,v,xxx = validation(B_all_list_2[i],test_speech,\n",
        "                    test_music,\n",
        "                    smr=s,\n",
        "                    iterations=it,\n",
        "                    m_component=Q,\n",
        "                    s_component=Q)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ok\n",
            "Separation finish ! ....\n",
            "Evaluation .....\n",
            "SMR =0 N_components =2: \n",
            "SDR Speech = 2.9348455449606248\n",
            "SDR Music  = 0.4769865169695596\n",
            "1022.1629455308959\n",
            "ok\n",
            "Separation finish ! ....\n",
            "Evaluation .....\n",
            "SMR =0 N_components =2: \n",
            "SDR Speech = 3.2005014293463327\n",
            "SDR Music  = 0.7426424013552673\n",
            "841.1128885143034\n",
            "ok\n",
            "Separation finish ! ....\n",
            "Evaluation .....\n",
            "SMR =0 N_components =2: \n",
            "SDR Speech = 3.5896611298929466\n",
            "SDR Music  = 1.1318021019018816\n",
            "738.8676148861664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeZ3fIJPYyTs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}