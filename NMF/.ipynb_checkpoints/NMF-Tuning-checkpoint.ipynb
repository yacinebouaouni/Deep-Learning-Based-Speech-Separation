{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 1000000\n",
      "Length : 22.68s\n",
      "Sample rate : 44100\n",
      "Shape of the music 1000000\n",
      "Length : 22.68s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "samplerate_s, data_speech = read(\"../data/male_vocal.wav\")\n",
    "speech=data_speech[:1000000,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(speech.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../data/piano.wav\")\n",
    "music=data_music[:speech.shape[0],0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n",
    "\n",
    "samplerate_t, test = read(\"../data/mixed_signal.wav\")\n",
    "test=test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed,_,_=get_mixed_signal(speech, music, 10)\n",
    "write(\"../../mixed.wav\", samplerate_s, mixed.astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply STFT :\n",
    "\n",
    "### We can change :\n",
    "\n",
    "* Window : Type of window\n",
    "* nperseg : length of window\n",
    "* noverlap : overlap between windows.\n",
    "* nfft : fft length > window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test,speech,music=get_mixed_signal(speech,music,10)\n",
    "\n",
    "WINDOW = 'hamming'\n",
    "WINDOW_SIZE=480\n",
    "OVERLAP = 0.6 * WINDOW_SIZE\n",
    "NFFT=512\n",
    "\n",
    "f,t,Y= signal.stft(speech,samplerate_s,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_s=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(music,samplerate_m,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_m=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(test,samplerate_t,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_t=np.abs(Y)\n",
    "print('Shape of spectrogram speech : {}'.format(Yabs_s.shape))\n",
    "print('Shape of spectrogram music: {}'.format(Yabs_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we apply the elbow method the optimal number of componenets will be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yabs_s[Yabs_s==0]=0.0001\n",
    "Yabs_t[Yabs_t==0]=0.0001\n",
    "Yabs_m[Yabs_m==0]=0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(speech, music,Ns,Nm,SMR_db,samplerate,p):\n",
    "    \n",
    "    \n",
    "    test,speech,music=get_mixed_signal(speech,music,SMR_db)\n",
    "\n",
    "    WINDOW = 'hamming'\n",
    "    WINDOW_SIZE=480\n",
    "    OVERLAP = 0.6 * WINDOW_SIZE\n",
    "    NFFT=512\n",
    "\n",
    "    f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_s=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_m=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_t=np.abs(Y)\n",
    "    \n",
    "    Yabs_s[Yabs_s==0]=0.0001\n",
    "    Yabs_t[Yabs_t==0]=0.0001\n",
    "    Yabs_m[Yabs_m==0]=0.0001\n",
    "\n",
    "    model = NMF(n_components=Ns, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=500, random_state=0)\n",
    "    G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "    B_s = model.components_\n",
    "    model = NMF(n_components=Nm, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=500, random_state=0)\n",
    "    G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "    B_m = model.components_\n",
    "\n",
    "    B=np.vstack([B_s,B_m])\n",
    "    model_test = NMF(n_components=Ns+Nm, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=200, random_state=0)\n",
    "    model_test.fit(np.transpose(Yabs_t))\n",
    "    \n",
    "    model_test.components_=B\n",
    "    G_test=model_test.transform(np.transpose(Yabs_t))\n",
    "    \n",
    "    \n",
    "    Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=Ns,Nm=Nm,Yabs=Y,p=p)\n",
    "    \n",
    "    speech_est = Sources[0]\n",
    "    music_est = Sources[1]\n",
    "    \n",
    "    _, speech_est =  signal.istft(speech_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    _, music_est =  signal.istft(music_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    speech_est = speech_est[:speech.shape[0]]\n",
    "    music_est = music_est[:music.shape[0]]\n",
    "    \n",
    "    sdr_speech = SDR(s_est=speech_est,s=speech)\n",
    "    sdr_music = SDR(s_est=music_est, s=music)\n",
    "    \n",
    "    return sdr_speech, sdr_music\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation SMR = -5 Ns = Nm = 2\n",
      "SMR = -5.00\n",
      "Speech SDR = 0.8101522635942392 ... Music SDR = 0.14231450338366675\n",
      "Evaluation SMR = -5 Ns = Nm = 16\n",
      "SMR = -5.00\n",
      "Speech SDR = -0.20046759323667557 ... Music SDR = 0.31309292526593824\n",
      "Evaluation SMR = -5 Ns = Nm = 32\n",
      "SMR = -5.00\n",
      "Speech SDR = 1.684163700257052 ... Music SDR = 0.11236404128305448\n",
      "Evaluation SMR = -5 Ns = Nm = 64\n",
      "SMR = -5.00\n",
      "Speech SDR = 1.93543522317764 ... Music SDR = 0.07960454156636225\n",
      "Evaluation SMR = -5 Ns = Nm = 128\n",
      "SMR = -5.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████████▋                                                       | 1/3 [03:14<06:29, 194.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech SDR = 0.6998553885972397 ... Music SDR = 0.3331371889440516\n",
      "Evaluation SMR = 0 Ns = Nm = 2\n",
      "Speech SDR = 2.116185479350049 ... Music SDR = -1.3399901786370763\n",
      "Evaluation SMR = 0 Ns = Nm = 16\n",
      "Speech SDR = 0.7650401319837625 ... Music SDR = -0.2952444223844851\n",
      "Evaluation SMR = 0 Ns = Nm = 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7c7d02d4152a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Evaluation SMR = {} Ns = Nm = {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSMR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0msdr_speech\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msdr_music\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmusic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmusic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSMR_db\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSMR\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msamplerate_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mSDR_SPEECH_Ncomp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdr_speech\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mSDR_MUSIC_Ncomp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msdr_music\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f3e90acef4d1>\u001b[0m in \u001b[0;36mEvaluation\u001b[1;34m(speech, music, Ns, Nm, SMR_db, samplerate)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mB_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'random'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta_loss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'itakura-saito'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mG_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYabs_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mB_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, W, H)\u001b[0m\n\u001b[0;32m   1285\u001b[0m             \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'both'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1287\u001b[1;33m             shuffle=self.shuffle)\n\u001b[0m\u001b[0;32m   1288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1289\u001b[0m         self.reconstruction_err_ = _beta_divergence(X, W, H, self.beta_loss,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36mnon_negative_factorization\u001b[1;34m(X, W, H, n_components, init, update_H, solver, beta_loss, tol, max_iter, alpha, l1_ratio, regularization, random_state, verbose, shuffle)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                                                   \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m                                                   \u001b[0ml2_reg_W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg_H\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m                                                   verbose)\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_fit_multiplicative_update\u001b[1;34m(X, W, H, beta_loss, max_iter, tol, l1_reg_W, l1_reg_H, l2_reg_W, l2_reg_H, update_H, verbose)\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdate_H\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m             delta_H = _multiplicative_update_h(X, W, H, beta_loss, l1_reg_H,\n\u001b[1;32m--> 812\u001b[1;33m                                                l2_reg_H, gamma)\n\u001b[0m\u001b[0;32m    813\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mdelta_H\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py\u001b[0m in \u001b[0;36m_multiplicative_update_h\u001b[1;34m(X, W, H, beta_loss, l1_reg_H, l2_reg_H, gamma)\u001b[0m\n\u001b[0;32m    655\u001b[0m             \u001b[1;31m# speeds up computation time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[1;31m# refer to /numpy/numpy/issues/9363\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[0mWH_safe_X_data\u001b[0m \u001b[1;33m**=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m             \u001b[0mWH_safe_X_data\u001b[0m \u001b[1;33m**=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             \u001b[1;31m# element-wise multiplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SDR_MUSIC=[]\n",
    "SDR_SPEECH=[]\n",
    "\n",
    "for SMR in tqdm([-5,0,5]):\n",
    "    \n",
    "    SDR_MUSIC_Ncomp=[]\n",
    "    SDR_SPEECH_Ncomp=[]\n",
    "    \n",
    "    for Ns in [2,16,32,64,128]:\n",
    "            \n",
    "            SDR_MUSIC_P=[]\n",
    "            SDR_SPEECH_P=[]\n",
    "\n",
    "            for p in [1,2,10]:\n",
    "                \n",
    "                print('Evaluation SMR = {} Ns = Nm = {}'.format(SMR,Ns))\n",
    "                sdr_speech,sdr_music=Evaluation(speech=speech, music=music,Ns=Ns,Nm=Ns,SMR_db=SMR,samplerate=samplerate_s,p=p)\n",
    "                SDR_SPEECH_Ncomp.append(sdr_speech)\n",
    "                SDR_MUSIC_Ncomp.append(sdr_music)\n",
    "                print('Speech SDR = {} ... Music SDR = {}'.format(sdr_speech,sdr_music))\n",
    "\n",
    "    SDR_MUSIC.append(SDR_MUSIC_Ncomp)\n",
    "    SDR_SPEECH.append(SDR_SPEECH_Ncomp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDR_MUSIC_ARRAY=np.array(SDR_MUSIC)\n",
    "SDR_SPEECH_ARRAY=np.array(SDR_SPEECH)\n",
    "np.save('./SDR/Music_sdr',SDR_MUSIC_ARRAY)\n",
    "np.save('./SDR/Speech_sdr',SDR_SPEECH_ARRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    \n",
    "    _, xrec =  signal.istft(Sources[i],\n",
    "                          samplerate_t,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    write(\"../../example\"+str(i)+\".wav\", samplerate_t, xrec.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
