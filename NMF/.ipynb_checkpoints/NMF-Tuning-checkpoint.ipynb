{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 26019000\n",
      "Length : 590.00s\n",
      "Sample rate : 44100\n",
      "Shape of the music 26019000\n",
      "Length : 590.00s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "N_minutes = 10*60*44100\n",
    "samplerate_s, data_speech = read(\"../../DATA/vocal_11.wav\")\n",
    "speech=data_speech[44100*10:N_minutes,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(speech.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../../DATA/piano_10.wav\")\n",
    "music=data_music[44100*10:N_minutes,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled rate = 22050\n"
     ]
    }
   ],
   "source": [
    "rate = 2\n",
    "speech = signal.resample(speech,int(speech.shape[0]/rate))\n",
    "music=signal.resample(music,int(music.shape[0]/rate))\n",
    "samplerate_m=int(samplerate_m/rate)\n",
    "samplerate_s=samplerate_m\n",
    "\n",
    "\n",
    "print('Downsampled rate = {}'.format(samplerate_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on one configuration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate_t=samplerate_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(speech, music,Ns,Nm,SMR_db,samplerate,p):\n",
    "    \n",
    "    # Set the test data:\n",
    "    test,speech_test,music_test=get_mixed_signal(speech,music,SMR_db)\n",
    "    test=test[5*882000:6*882000]\n",
    "    speech_test=speech_test[5*882000:6*882000]\n",
    "    music_test = music_test[5*882000:6*882000]\n",
    "    \n",
    "    write(\"../../Tests/Test.wav\", samplerate_t, test.astype(np.int16))\n",
    "    \n",
    "    WINDOW = 'hamming'\n",
    "    WINDOW_SIZE=256\n",
    "    OVERLAP = 0.6 * WINDOW_SIZE\n",
    "    NFFT=512\n",
    "\n",
    "    f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_s=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_m=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_t=np.abs(Y)\n",
    "    \n",
    "    Yabs_s[Yabs_s==0]=0.0001\n",
    "    Yabs_t[Yabs_t==0]=0.0001\n",
    "    Yabs_m[Yabs_m==0]=0.0001\n",
    "\n",
    "    model = NMF(n_components=Ns, init='random',alpha=0.2,beta_loss='itakura-saito',solver=\"mu\",max_iter=20, random_state=0)\n",
    "    G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "    B_s = model.components_\n",
    "    \n",
    "    print('Training Speech NMF  .... Done')\n",
    "    \n",
    "    model = NMF(n_components=Nm, init='random',alpha=0.2,beta_loss='itakura-saito',solver=\"mu\",max_iter=20, random_state=0)\n",
    "    G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "    B_m = model.components_\n",
    "\n",
    "    print('Training Music NMF .... Done')\n",
    "\n",
    "    B=np.vstack([B_s,B_m])\n",
    "    \n",
    "    \n",
    "    model_test = NMF(n_components=Ns+Nm, init='random',alpha=0.2,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    model_test.fit(np.transpose(Yabs_t))\n",
    "    \n",
    "    model_test.components_=B\n",
    "    G_test=model_test.transform(np.transpose(Yabs_t))\n",
    "    \n",
    "    print('Testing NMF .... Done')\n",
    "    Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=Ns,Nm=Nm,Yabs=Y,p=p)\n",
    "    \n",
    "    print('Reconstruction Step .... Done')\n",
    "    speech_est = Sources[0]\n",
    "    music_est = Sources[1]\n",
    "    \n",
    "    _, speech_est =  signal.istft(speech_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    _, music_est =  signal.istft(music_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    speech_est = speech_est[:speech_test.shape[0]]\n",
    "    music_est = music_est[:music_test.shape[0]]\n",
    "    \n",
    "    sdr_speech = SDR(s_est=speech_est,s=speech_test)\n",
    "    sdr_music = SDR(s_est=music_est, s=music_test)\n",
    "    \n",
    "    print('SDR Speech = {:.2f} ... SDR Music = {:.2f}'.format(sdr_speech,sdr_music))\n",
    "    \n",
    "    write(\"../../Tests/SpeechX.wav\", samplerate_t, speech_est.astype(np.int16))\n",
    "    write(\"../../Tests/MusicX.wav\", samplerate_t, music_est.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMR = 0.00\n",
      "Training Speech NMF  .... Done\n",
      "Training Music NMF .... Done\n",
      "Testing NMF .... Done\n",
      "Reconstruction Step .... Done\n",
      "SDR Speech = 0.27 ... SDR Music = 2.71\n"
     ]
    }
   ],
   "source": [
    "Test(speech=speech, music=music,Ns=64,Nm=64,SMR_db=0,samplerate=samplerate_m,p=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
