{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 5018580\n",
      "Length : 113.80s\n",
      "Sample rate : 44100\n",
      "Shape of the music 5046139\n",
      "Length : 114.42s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "samplerate_s, data_speech = read(\"../data/male_vocal.wav\")\n",
    "speech=data_speech[:100000000,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(speech.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../data/piano.wav\")\n",
    "music=data_music[:100000000,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n",
    "\n",
    "samplerate_t, test = read(\"../data/mixed_signal.wav\")\n",
    "test=test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDR(s_est, s):\n",
    "    \"\"\"\n",
    "    Function that takes original and estimated spectrogram\n",
    "    return SDR in DB\n",
    "    \"\"\"\n",
    "    \n",
    "    signal_power = torch.tensor(s,dtype=torch.float64).norm(p=2)\n",
    "    distorsion_power = torch.tensor(s-s_est,dtype=torch.float64).norm(p=2)\n",
    "    SDR_db=10*np.log10(signal_power/distorsion_power)\n",
    "    \n",
    "    return SDR_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply STFT :\n",
    "\n",
    "### We can change :\n",
    "\n",
    "* Window : Type of window\n",
    "* nperseg : length of window\n",
    "* noverlap : overlap between windows.\n",
    "* nfft : fft length > window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spectrogram speech : (257, 26140)\n",
      "Shape of spectrogram music: (257, 26283)\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 'hamming'\n",
    "WINDOW_SIZE=480\n",
    "OVERLAP = 0.6 * WINDOW_SIZE\n",
    "NFFT=512\n",
    "\n",
    "f,t,Y= signal.stft(speech,samplerate_s,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_s=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(music,samplerate_m,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_m=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(test,samplerate_t,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_t=np.abs(Y)\n",
    "print('Shape of spectrogram speech : {}'.format(Yabs_s.shape))\n",
    "print('Shape of spectrogram music: {}'.format(Yabs_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we apply the elbow method the optimal number of componenets will be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yabs_s[Yabs_s==0]=0.0001\n",
    "Yabs_t[Yabs_t==0]=0.0001\n",
    "Yabs_m[Yabs_m==0]=0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=64, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "B_s = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=64, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "B_m = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 257)\n"
     ]
    }
   ],
   "source": [
    "B=np.vstack([B_s,B_m])\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = NMF(n_components=128, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "model_test.fit(np.transpose(Yabs_t))\n",
    "model_test.components_=B\n",
    "G_test=model_test.transform(np.transpose(Yabs_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape = (257, 26283)\n"
     ]
    }
   ],
   "source": [
    "Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=64,Nm=64,Yabs=Y,p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    \n",
    "    _, xrec =  signal.istft(Sources[i],\n",
    "                          samplerate_t,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    write(\"../../example\"+str(i)+\".wav\", samplerate_t, xrec.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
