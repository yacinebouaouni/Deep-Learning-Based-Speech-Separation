{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y,SMR,get_mixed_signal,SDR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 18081000\n",
      "Length : 410.00s\n",
      "Sample rate : 44100\n",
      "Shape of the music 18081000\n",
      "Length : 410.00s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "N_minutes = 7*60*44100\n",
    "samplerate_s, data_speech = read(\"../../DATA/vocal_11.wav\")\n",
    "speech=data_speech[44100*10:N_minutes,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(speech.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../../DATA/piano_10.wav\")\n",
    "music=data_music[44100*10:N_minutes,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply STFT :\n",
    "\n",
    "### We can change :\n",
    "\n",
    "* Window : Type of window\n",
    "* nperseg : length of window\n",
    "* noverlap : overlap between windows.\n",
    "* nfft : fft length > window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test,speech,music=get_mixed_signal(speech,music,10)\n",
    "\n",
    "WINDOW = 'hamming'\n",
    "WINDOW_SIZE=480\n",
    "OVERLAP = 0.6 * WINDOW_SIZE\n",
    "NFFT=512\n",
    "\n",
    "f,t,Y= signal.stft(speech,samplerate_s,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_s=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(music,samplerate_m,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_m=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(test,samplerate_t,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_t=np.abs(Y)\n",
    "print('Shape of spectrogram speech : {}'.format(Yabs_s.shape))\n",
    "print('Shape of spectrogram music: {}'.format(Yabs_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Loop :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Evaluation(speech, music,Ns,Nm,SMR_db,samplerate,p):\n",
    "    \n",
    "    \n",
    "    test,speech_test,music_test=get_mixed_signal(speech,music,SMR_db)\n",
    "    test=test[882000:2*882000]\n",
    "    speech_test=speech_test[882000:2*882000]\n",
    "    music_test = music_test[882000:2*882000]\n",
    "    \n",
    "    WINDOW = 'hamming'\n",
    "    WINDOW_SIZE=480\n",
    "    OVERLAP = 0.6 * WINDOW_SIZE\n",
    "    NFFT=512\n",
    "\n",
    "    f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_s=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_m=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_t=np.abs(Y)\n",
    "    \n",
    "    Yabs_s[Yabs_s==0]=0.0001\n",
    "    Yabs_t[Yabs_t==0]=0.0001\n",
    "    Yabs_m[Yabs_m==0]=0.0001\n",
    "\n",
    "    model = NMF(n_components=Ns, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "    B_s = model.components_\n",
    "    \n",
    "    \n",
    "    model = NMF(n_components=Nm, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "    B_m = model.components_\n",
    "\n",
    "    B=np.vstack([B_s,B_m])\n",
    "    \n",
    "    \n",
    "    model_test = NMF(n_components=Ns+Nm, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    model_test.fit(np.transpose(Yabs_t))\n",
    "    \n",
    "    model_test.components_=B\n",
    "    G_test=model_test.transform(np.transpose(Yabs_t))\n",
    "    \n",
    "    \n",
    "    Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=Ns,Nm=Nm,Yabs=Y,p=p)\n",
    "    \n",
    "    speech_est = Sources[0]\n",
    "    music_est = Sources[1]\n",
    "    \n",
    "    _, speech_est =  signal.istft(speech_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    _, music_est =  signal.istft(music_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    speech_est = speech_est[:speech_test.shape[0]]\n",
    "    music_est = music_est[:music_test.shape[0]]\n",
    "    \n",
    "    sdr_speech = SDR(s_est=speech_est,s=speech_test)\n",
    "    sdr_music = SDR(s_est=music_est, s=music_test)\n",
    "    \n",
    "    return sdr_speech, sdr_music\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDR_MUSIC=[]\n",
    "SDR_SPEECH=[]\n",
    "\n",
    "for SMR in tqdm([0]):\n",
    "    \n",
    "    SDR_MUSIC_Ncomp=[]\n",
    "    SDR_SPEECH_Ncomp=[]\n",
    "    \n",
    "    for Ns in tqdm([2,64,128]):\n",
    "            \n",
    "            SDR_MUSIC_P=[]\n",
    "            SDR_SPEECH_P=[]\n",
    "\n",
    "            for p in [2]:\n",
    "                \n",
    "                print('Evaluation SMR = {} Ns = Nm = {} p = {}'.format(SMR,Ns,p))\n",
    "                sdr_speech,sdr_music=Evaluation(speech=speech, music=music,Ns=Ns,Nm=Ns,SMR_db=SMR,samplerate=samplerate_s,p=p)\n",
    "                SDR_SPEECH_P.append(sdr_speech)\n",
    "                SDR_MUSIC_P.append(sdr_music)\n",
    "                print('Speech SDR = {} ... Music SDR = {}'.format(sdr_speech,sdr_music))\n",
    "\n",
    "            SDR_MUSIC_Ncomp.append(SDR_MUSIC_P)\n",
    "            SDR_SPEECH_Ncomp.append(SDR_SPEECH_P)\n",
    "            \n",
    "    SDR_MUSIC.append(SDR_MUSIC_Ncomp)\n",
    "    SDR_SPEECH.append(SDR_SPEECH_Ncomp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDR_MUSIC_ARRAY=np.array(SDR_MUSIC)\n",
    "SDR_SPEECH_ARRAY=np.array(SDR_SPEECH)\n",
    "np.save('./SDR/Music_sdr2',SDR_MUSIC_ARRAY)\n",
    "np.save('./SDR/Speech_sdr2',SDR_SPEECH_ARRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on one configuration :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test(speech, music,Ns,Nm,SMR_db,samplerate,p):\n",
    "    \n",
    "    \n",
    "    test,speech_test,music_test=get_mixed_signal(speech,music,SMR_db)\n",
    "    test=test[882000:3*882000]\n",
    "    speech_test=speech_test[882000:3*882000]\n",
    "    music_test = music_test[882000:3*882000]\n",
    "    \n",
    "    write(\"../../Tests/Test.wav\", samplerate_t, test.astype(np.int16))\n",
    "    \n",
    "    WINDOW = 'hamming'\n",
    "    WINDOW_SIZE=480\n",
    "    OVERLAP = 0.6 * WINDOW_SIZE\n",
    "    NFFT=512\n",
    "\n",
    "    f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_s=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_m=np.abs(Y)\n",
    "\n",
    "    f,t,Y= signal.stft(test,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "    Yabs_t=np.abs(Y)\n",
    "    \n",
    "    Yabs_s[Yabs_s==0]=0.0001\n",
    "    Yabs_t[Yabs_t==0]=0.0001\n",
    "    Yabs_m[Yabs_m==0]=0.0001\n",
    "\n",
    "    model = NMF(n_components=Ns, init='random',alpha=0.5,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "    B_s = model.components_\n",
    "    \n",
    "    print('Train NMF 1 ... Done')\n",
    "    \n",
    "    model = NMF(n_components=Nm, init='random',alpha=0.5,beta_loss='itakura-saito',solver=\"mu\",max_iter=50, random_state=0)\n",
    "    G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "    B_m = model.components_\n",
    "\n",
    "    print('Train NMF 2 ... Done')\n",
    "\n",
    "    B=np.vstack([B_s,B_m])\n",
    "    \n",
    "    \n",
    "    model_test = NMF(n_components=Ns+Nm, init='random',alpha=0.5,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "    model_test.fit(np.transpose(Yabs_t))\n",
    "    \n",
    "    model_test.components_=B\n",
    "    G_test=model_test.transform(np.transpose(Yabs_t))\n",
    "    \n",
    "    \n",
    "    Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=Ns,Nm=Nm,Yabs=Y,p=p)\n",
    "    \n",
    "    speech_est = Sources[0]\n",
    "    music_est = Sources[1]\n",
    "    \n",
    "    _, speech_est =  signal.istft(speech_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    _, music_est =  signal.istft(music_est,\n",
    "                          samplerate,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    \n",
    "    speech_est = speech_est[:speech_test.shape[0]]\n",
    "    music_est = music_est[:music_test.shape[0]]\n",
    "    \n",
    "    sdr_speech = SDR(s_est=speech_est,s=speech_test)\n",
    "    sdr_music = SDR(s_est=music_est, s=music_test)\n",
    "    \n",
    "    print('SDR Speech = {:.2f} ... SDR Music = {:.2f}'.format(sdr_speech,sdr_music))\n",
    "    \n",
    "    write(\"../../Tests/Speech.wav\", samplerate_t, speech_est.astype(np.int16))\n",
    "    write(\"../../Tests/Music.wav\", samplerate_t, music_est.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train NMF 1 ... Done\n",
      "Train NMF 2 ... Done\n",
      "SDR Speech = 0.68 ... SDR Music = -2.12\n"
     ]
    }
   ],
   "source": [
    "Test(speech=speech, music=music,Ns=8,Nm=8,SMR_db=0,samplerate=samplerate_s,p=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
