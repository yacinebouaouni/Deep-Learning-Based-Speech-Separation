{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y,SMR\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import torch\n",
    "import math\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 1000000\n",
      "Length : 22.68s\n",
      "Sample rate : 44100\n",
      "Shape of the music 1000000\n",
      "Length : 22.68s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "samplerate_s, data_speech = read(\"../data/male_vocal.wav\")\n",
    "speech=data_speech[:1000000,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(speech.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../data/piano.wav\")\n",
    "music=data_music[:1000000,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n",
    "\n",
    "samplerate_t, test = read(\"../data/mixed_signal.wav\")\n",
    "test=test[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SMR = 2.43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.4260, dtype=torch.float64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMR(speech,music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SMR = 10.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([    4.0000,     4.0000,     4.0000,  ..., -3053.7181, -2832.1956,\n",
       "        -3028.2358], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mixed_signal(speech, music, SMR_db):\n",
    "    \"\"\"\n",
    "    Function taht takes the speech and music signal alongside the SMR_db\n",
    "    returns the mixed signal and the scaled speech\n",
    "    \"\"\"\n",
    "    smr = 10**(SMR_db/10)\n",
    "    speech_power = torch.tensor(speech,dtype=torch.float64).norm(p=2)\n",
    "    music_power = torch.tensor(music,dtype=torch.float64).norm(p=2)\n",
    "    scale = smr * music_power / speech_power\n",
    "    \n",
    "    if SMR_db ==0:\n",
    "        mixed = speech + music\n",
    "        return mixed,speech,music\n",
    "    \n",
    "    if SMR_db < 0 :\n",
    "        mixed = scale* speech + music\n",
    "        speech_scaled=scale*speech\n",
    "        SMR(speech_scaled,music)\n",
    "        return mixed,speech_scaled,music\n",
    "    \n",
    "    if SMR_db >0 :\n",
    "        \n",
    "        mixed =  speech + music * (1/scale)\n",
    "        music_scaled=(1/scale) * music\n",
    "        SMR(speech,music_scaled)\n",
    "        return mixed,speech,music_scaled\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SMR = 5.00\n"
     ]
    }
   ],
   "source": [
    "mixed=get_mixed_signal(speech, music, 5)\n",
    "write(\"../../mixed.wav\", samplerate_s, mixed.detach().numpy().astype(np.int16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply STFT :\n",
    "\n",
    "### We can change :\n",
    "\n",
    "* Window : Type of window\n",
    "* nperseg : length of window\n",
    "* noverlap : overlap between windows.\n",
    "* nfft : fft length > window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spectrogram speech : (257, 26140)\n",
      "Shape of spectrogram music: (257, 26283)\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 'hamming'\n",
    "WINDOW_SIZE=480\n",
    "OVERLAP = 0.6 * WINDOW_SIZE\n",
    "NFFT=512\n",
    "\n",
    "f,t,Y= signal.stft(speech,samplerate_s,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_s=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(music,samplerate_m,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_m=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(test,samplerate_t,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_t=np.abs(Y)\n",
    "print('Shape of spectrogram speech : {}'.format(Yabs_s.shape))\n",
    "print('Shape of spectrogram music: {}'.format(Yabs_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we apply the elbow method the optimal number of componenets will be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yabs_s[Yabs_s==0]=0.0001\n",
    "Yabs_t[Yabs_t==0]=0.0001\n",
    "Yabs_m[Yabs_m==0]=0.0001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=64, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "B_s = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=64, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "B_m = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 257)\n"
     ]
    }
   ],
   "source": [
    "B=np.vstack([B_s,B_m])\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = NMF(n_components=128, init='random',alpha=0.7,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "model_test.fit(np.transpose(Yabs_t))\n",
    "model_test.components_=B\n",
    "G_test=model_test.transform(np.transpose(Yabs_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source shape = (257, 26283)\n"
     ]
    }
   ],
   "source": [
    "Sources,Masks=Reconstruct(B=np.transpose(B),G=np.transpose(G_test),Ns=64,Nm=64,Yabs=Y,p=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    \n",
    "    _, xrec =  signal.istft(Sources[i],\n",
    "                          samplerate_t,\n",
    "                          window = WINDOW,\n",
    "                          nperseg=WINDOW_SIZE,\n",
    "                          noverlap=OVERLAP,\n",
    "                          nfft = NFFT)\n",
    "    write(\"../../example\"+str(i)+\".wav\", samplerate_t, xrec.astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
