{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import read, write\n",
    "from scipy import signal\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy.linalg import inv\n",
    "from helpers import Reconstruct, Viz_Y\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Read speech and music data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the speech 100000\n",
      "Length : 0.23s\n",
      "Sample rate : 44100\n",
      "Shape of the music 100000\n",
      "Length : 2.27s\n",
      "Sample rate : 44100\n"
     ]
    }
   ],
   "source": [
    "samplerate_s, data_speech = read(\"../data/male_vocal.wav\")\n",
    "speech=data_speech[:10000,0]\n",
    "length=speech.shape[0]/samplerate_s\n",
    "print('Shape of the speech {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_s))\n",
    "\n",
    "samplerate_m, data_music = read(\"../data/piano.wav\")\n",
    "music=data_music[:100000,0]\n",
    "length=music.shape[0]/samplerate_m\n",
    "print('Shape of the music {}'.format(music.shape[0]))\n",
    "print('Length : {:.2f}s'.format(length))\n",
    "print('Sample rate : {}'.format(samplerate_m))\n",
    "\n",
    "samplerate_t, test = read(\"../data/mixed_signal.wav\")\n",
    "test=test[:100000,0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply STFT :\n",
    "\n",
    "### We can change :\n",
    "\n",
    "* Window : Type of window\n",
    "* nperseg : length of window\n",
    "* noverlap : overlap between windows.\n",
    "* nfft : fft length > window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of spectrogram speech : (257, 54)\n",
      "Shape of spectrogram music: (257, 522)\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 'hamming'\n",
    "WINDOW_SIZE=480\n",
    "OVERLAP = 0.6 * WINDOW_SIZE\n",
    "NFFT=512\n",
    "\n",
    "f,t,Y= signal.stft(speech,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_s=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(music,samplerate,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_m=np.abs(Y)\n",
    "\n",
    "f,t,Y= signal.stft(test,samplerate_t,window=WINDOW,nperseg=WINDOW_SIZE,noverlap=OVERLAP,nfft=NFFT)\n",
    "Yabs_t=np.abs(Y)\n",
    "print('Shape of spectrogram speech : {}'.format(Yabs_s.shape))\n",
    "print('Shape of spectrogram music: {}'.format(Yabs_m.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we apply the elbow method the optimal number of componenets will be 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=8, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_s = model.fit_transform(np.transpose(Yabs_s))\n",
    "B_s = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NMF(n_components=8, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "G_m = model.fit_transform(np.transpose(Yabs_m))\n",
    "B_m = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 257)\n"
     ]
    }
   ],
   "source": [
    "B=np.vstack([B_s,B_m])\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = NMF(n_components=16, init='random',alpha=0.0,beta_loss='itakura-saito',solver=\"mu\",max_iter=100, random_state=0)\n",
    "model_test.fit(np.transpose(Yabs_t))\n",
    "model_test.components_=B\n",
    "G_test=model_test.transform(np.transpose(Yabs_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 522)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.transpose(B),np.transpose(G_test)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation of the magnitude of the sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percents = pourcentage(n_components,B,G)\n",
    "Sources=[]\n",
    "\n",
    "for i in range(n_components):\n",
    "    \n",
    "    Sources.append(np.multiply(percents[i],Yabs))\n",
    "    \n",
    "print('Source shape = {}'.format(Sources[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,n_components,figsize=(20,8))\n",
    "\n",
    "for i in range(n_components):\n",
    "        \n",
    "        ax[i].pcolormesh(t, f,Sources[i],vmin=0, vmax=20, shading='gouraud')\n",
    "        ax[i].set_title('STFT Magnitude')\n",
    "        ax[i].set_ylabel('Frequency [Hz]')\n",
    "        ax[i].set_xlabel('Time [sec]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_components):\n",
    "    \n",
    "    _, xrec =  signal.istft(Sources[i],\n",
    "                          samplerate,\n",
    "                          window = \"hamming\",\n",
    "                          nperseg=480,\n",
    "                          noverlap=480*0.5,\n",
    "                          nfft = 512)\n",
    "    write(\"../data/example\"+str(i)+\".wav\", samplerate, xrec.astype(np.int16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
